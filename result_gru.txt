Namespace(batch_size=64, dict='data/CBTest/data/cbtest_NE_train.txtdict.pt', dropout=0.1, embed_size=384, epochs=10, gpu=0, gru_size=384, learning_rate=0.001, log_interval=50, save_model='model2', start_epoch=1, train_from='', traindata='data/CBTest/data/cbtest_NE_train.txt.pt', validdata='data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt', weight_decay=0.0001)
('Loading dictrionary from ', 'data/CBTest/data/cbtest_NE_train.txtdict.pt')
('Loading train data from ', 'data/CBTest/data/cbtest_NE_train.txt.pt')
('Loading valid data from ', 'data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt')
 * vocabulary size = 15683
 * number of training samples. 108719
 * maximum batch size. 64
Building model...
* number of parameters: 7796352
AoAReader(
  (embedding): Embedding(15683, 384, padding_idx=0)
  (gru): GRU(384, 384, batch_first=True, dropout=0.1, bidirectional=True)
)

Epoch  1,     1/ 1699; avg loss: 4.30; acc:  48.44;       2 s elapsed
Epoch  1,    51/ 1699; avg loss: 2.69; acc:  46.84;      69 s elapsed
Epoch  1,   101/ 1699; avg loss: 1.93; acc:  48.62;     135 s elapsed
Epoch  1,   151/ 1699; avg loss: 1.70; acc:  50.47;     201 s elapsed
Epoch  1,   201/ 1699; avg loss: 1.66; acc:  50.78;     267 s elapsed
Epoch  1,   251/ 1699; avg loss: 1.53; acc:  54.78;     334 s elapsed
Epoch  1,   301/ 1699; avg loss: 1.38; acc:  58.47;     400 s elapsed
Epoch  1,   351/ 1699; avg loss: 1.33; acc:  60.00;     465 s elapsed
Epoch  1,   401/ 1699; avg loss: 1.19; acc:  63.03;     530 s elapsed
Epoch  1,   451/ 1699; avg loss: 1.15; acc:  64.81;     595 s elapsed
Epoch  1,   501/ 1699; avg loss: 1.09; acc:  66.12;     659 s elapsed
Epoch  1,   551/ 1699; avg loss: 1.07; acc:  66.16;     725 s elapsed
Epoch  1,   601/ 1699; avg loss: 0.99; acc:  67.19;     789 s elapsed
Epoch  1,   651/ 1699; avg loss: 1.03; acc:  67.88;     855 s elapsed
Epoch  1,   701/ 1699; avg loss: 1.01; acc:  67.50;     919 s elapsed
Epoch  1,   751/ 1699; avg loss: 0.98; acc:  69.00;     984 s elapsed
Epoch  1,   801/ 1699; avg loss: 1.01; acc:  67.94;    1049 s elapsed
Epoch  1,   851/ 1699; avg loss: 0.97; acc:  68.50;    1115 s elapsed
Epoch  1,   901/ 1699; avg loss: 0.96; acc:  68.91;    1182 s elapsed
Epoch  1,   951/ 1699; avg loss: 0.93; acc:  70.50;    1247 s elapsed
Epoch  1,  1001/ 1699; avg loss: 0.91; acc:  70.50;    1313 s elapsed
Epoch  1,  1051/ 1699; avg loss: 0.90; acc:  69.81;    1377 s elapsed
Epoch  1,  1101/ 1699; avg loss: 0.91; acc:  70.56;    1443 s elapsed
Epoch  1,  1151/ 1699; avg loss: 0.85; acc:  72.06;    1508 s elapsed
Epoch  1,  1201/ 1699; avg loss: 0.89; acc:  69.81;    1574 s elapsed
Epoch  1,  1251/ 1699; avg loss: 0.88; acc:  70.66;    1639 s elapsed
Epoch  1,  1301/ 1699; avg loss: 0.87; acc:  72.66;    1703 s elapsed
Epoch  1,  1351/ 1699; avg loss: 0.91; acc:  70.78;    1768 s elapsed
Epoch  1,  1401/ 1699; avg loss: 0.86; acc:  72.09;    1833 s elapsed
Epoch  1,  1451/ 1699; avg loss: 0.82; acc:  72.84;    1898 s elapsed
Epoch  1,  1501/ 1699; avg loss: 0.86; acc:  71.03;    1963 s elapsed
Epoch  1,  1551/ 1699; avg loss: 0.86; acc:  72.31;    2029 s elapsed
Epoch  1,  1601/ 1699; avg loss: 0.84; acc:  72.12;    2096 s elapsed
Epoch  1,  1651/ 1699; avg loss: 0.83; acc:  72.69;    2152 s elapsed
Epoch 1:	 average loss: 1.11	 train accuracy: 66.1706
====================
Evaluating on validation set:
Validation loss: 1.28
Validation accuracy: 65
====================

Epoch  2,     1/ 1699; avg loss: 0.78; acc:  71.88;    2241 s elapsed
Epoch  2,    51/ 1699; avg loss: 0.75; acc:  74.75;    2307 s elapsed
Epoch  2,   101/ 1699; avg loss: 0.74; acc:  74.44;    2372 s elapsed
Epoch  2,   151/ 1699; avg loss: 0.78; acc:  73.94;    2437 s elapsed
Epoch  2,   201/ 1699; avg loss: 0.81; acc:  72.75;    2504 s elapsed
Epoch  2,   251/ 1699; avg loss: 0.80; acc:  73.22;    2569 s elapsed
Epoch  2,   301/ 1699; avg loss: 0.76; acc:  74.00;    2634 s elapsed
Epoch  2,   351/ 1699; avg loss: 0.83; acc:  72.03;    2700 s elapsed
Epoch  2,   401/ 1699; avg loss: 0.79; acc:  73.97;    2765 s elapsed
Epoch  2,   451/ 1699; avg loss: 0.76; acc:  74.62;    2831 s elapsed
Epoch  2,   501/ 1699; avg loss: 0.79; acc:  72.78;    2897 s elapsed
Epoch  2,   551/ 1699; avg loss: 0.74; acc:  75.22;    2962 s elapsed
Epoch  2,   601/ 1699; avg loss: 0.79; acc:  73.47;    3027 s elapsed
Epoch  2,   651/ 1699; avg loss: 0.75; acc:  74.41;    3092 s elapsed
Epoch  2,   701/ 1699; avg loss: 0.80; acc:  73.78;    3157 s elapsed
Epoch  2,   751/ 1699; avg loss: 0.77; acc:  73.44;    3222 s elapsed
Epoch  2,   801/ 1699; avg loss: 0.75; acc:  74.38;    3288 s elapsed
Epoch  2,   851/ 1699; avg loss: 0.78; acc:  73.12;    3353 s elapsed
Epoch  2,   901/ 1699; avg loss: 0.75; acc:  74.47;    3418 s elapsed
Epoch  2,   951/ 1699; avg loss: 0.81; acc:  73.09;    3483 s elapsed
Epoch  2,  1001/ 1699; avg loss: 0.79; acc:  72.56;    3548 s elapsed
Epoch  2,  1051/ 1699; avg loss: 0.79; acc:  73.81;    3613 s elapsed
Epoch  2,  1101/ 1699; avg loss: 0.73; acc:  75.47;    3679 s elapsed
Epoch  2,  1151/ 1699; avg loss: 0.77; acc:  73.62;    3744 s elapsed
Epoch  2,  1201/ 1699; avg loss: 0.77; acc:  73.44;    3809 s elapsed
Epoch  2,  1251/ 1699; avg loss: 0.76; acc:  74.78;    3874 s elapsed
Epoch  2,  1301/ 1699; avg loss: 0.74; acc:  74.38;    3940 s elapsed
Epoch  2,  1351/ 1699; avg loss: 0.75; acc:  75.09;    4006 s elapsed
Epoch  2,  1401/ 1699; avg loss: 0.79; acc:  72.47;    4071 s elapsed
Epoch  2,  1451/ 1699; avg loss: 0.75; acc:  73.50;    4137 s elapsed
Epoch  2,  1501/ 1699; avg loss: 0.76; acc:  74.31;    4203 s elapsed
Epoch  2,  1551/ 1699; avg loss: 0.79; acc:  72.47;    4269 s elapsed
Epoch  2,  1601/ 1699; avg loss: 0.78; acc:  74.03;    4334 s elapsed
Epoch  2,  1651/ 1699; avg loss: 0.75; acc:  75.25;    4390 s elapsed
Epoch 2:	 average loss: 0.77	 train accuracy: 73.8546
====================
Evaluating on validation set:
Validation loss: 1.30
Validation accuracy: 63.8
====================

Epoch  3,     1/ 1699; avg loss: 0.76; acc:  79.69;    4477 s elapsed
Epoch  3,    51/ 1699; avg loss: 0.64; acc:  78.81;    4542 s elapsed
Epoch  3,   101/ 1699; avg loss: 0.70; acc:  75.78;    4607 s elapsed
Epoch  3,   151/ 1699; avg loss: 0.64; acc:  77.69;    4672 s elapsed
Epoch  3,   201/ 1699; avg loss: 0.69; acc:  76.44;    4738 s elapsed
Epoch  3,   251/ 1699; avg loss: 0.68; acc:  76.91;    4804 s elapsed
Epoch  3,   301/ 1699; avg loss: 0.67; acc:  76.94;    4869 s elapsed
Epoch  3,   351/ 1699; avg loss: 0.74; acc:  74.22;    4935 s elapsed
Epoch  3,   401/ 1699; avg loss: 0.71; acc:  75.00;    5000 s elapsed
Epoch  3,   451/ 1699; avg loss: 0.74; acc:  74.84;    5065 s elapsed
Epoch  3,   501/ 1699; avg loss: 0.72; acc:  76.00;    5130 s elapsed
Epoch  3,   551/ 1699; avg loss: 0.70; acc:  75.56;    5195 s elapsed
Epoch  3,   601/ 1699; avg loss: 0.70; acc:  76.28;    5261 s elapsed
Epoch  3,   651/ 1699; avg loss: 0.68; acc:  76.34;    5326 s elapsed
Epoch  3,   701/ 1699; avg loss: 0.72; acc:  74.75;    5392 s elapsed
Epoch  3,   751/ 1699; avg loss: 0.72; acc:  76.16;    5458 s elapsed
Epoch  3,   801/ 1699; avg loss: 0.73; acc:  74.72;    5523 s elapsed
Epoch  3,   851/ 1699; avg loss: 0.69; acc:  76.03;    5589 s elapsed
Epoch  3,   901/ 1699; avg loss: 0.68; acc:  76.56;    5653 s elapsed
Epoch  3,   951/ 1699; avg loss: 0.71; acc:  75.41;    5718 s elapsed
Epoch  3,  1001/ 1699; avg loss: 0.75; acc:  74.53;    5784 s elapsed
Epoch  3,  1051/ 1699; avg loss: 0.69; acc:  76.66;    5849 s elapsed
Epoch  3,  1101/ 1699; avg loss: 0.73; acc:  74.91;    5915 s elapsed
Epoch  3,  1151/ 1699; avg loss: 0.67; acc:  77.09;    5980 s elapsed
Epoch  3,  1201/ 1699; avg loss: 0.71; acc:  75.81;    6046 s elapsed
Epoch  3,  1251/ 1699; avg loss: 0.74; acc:  75.03;    6111 s elapsed
Epoch  3,  1301/ 1699; avg loss: 0.69; acc:  76.59;    6176 s elapsed
Epoch  3,  1351/ 1699; avg loss: 0.73; acc:  74.97;    6240 s elapsed
Epoch  3,  1401/ 1699; avg loss: 0.71; acc:  75.88;    6306 s elapsed
Epoch  3,  1451/ 1699; avg loss: 0.70; acc:  76.00;    6372 s elapsed
Epoch  3,  1501/ 1699; avg loss: 0.71; acc:  75.50;    6438 s elapsed
Epoch  3,  1551/ 1699; avg loss: 0.73; acc:  75.50;    6503 s elapsed
Epoch  3,  1601/ 1699; avg loss: 0.74; acc:  74.25;    6568 s elapsed
Epoch  3,  1651/ 1699; avg loss: 0.72; acc:  75.91;    6623 s elapsed
Epoch 3:	 average loss: 0.71	 train accuracy: 75.8239
====================
Evaluating on validation set:
Validation loss: 1.17
Validation accuracy: 68.4
====================

Epoch  4,     1/ 1699; avg loss: 0.61; acc:  73.44;    6711 s elapsed
Epoch  4,    51/ 1699; avg loss: 0.62; acc:  79.41;    6775 s elapsed
Epoch  4,   101/ 1699; avg loss: 0.60; acc:  79.25;    6842 s elapsed
Epoch  4,   151/ 1699; avg loss: 0.62; acc:  78.31;    6908 s elapsed
Epoch  4,   201/ 1699; avg loss: 0.61; acc:  78.66;    6973 s elapsed
Epoch  4,   251/ 1699; avg loss: 0.64; acc:  78.56;    7038 s elapsed
Epoch  4,   301/ 1699; avg loss: 0.63; acc:  78.00;    7103 s elapsed
Epoch  4,   351/ 1699; avg loss: 0.66; acc:  77.16;    7169 s elapsed
Epoch  4,   401/ 1699; avg loss: 0.66; acc:  77.25;    7235 s elapsed
Epoch  4,   451/ 1699; avg loss: 0.67; acc:  77.75;    7300 s elapsed
Epoch  4,   501/ 1699; avg loss: 0.64; acc:  77.19;    7364 s elapsed
Epoch  4,   551/ 1699; avg loss: 0.65; acc:  77.59;    7431 s elapsed
Epoch  4,   601/ 1699; avg loss: 0.65; acc:  77.12;    7497 s elapsed
Epoch  4,   651/ 1699; avg loss: 0.68; acc:  75.72;    7562 s elapsed
Epoch  4,   701/ 1699; avg loss: 0.67; acc:  76.88;    7629 s elapsed
Epoch  4,   751/ 1699; avg loss: 0.67; acc:  76.34;    7694 s elapsed
Epoch  4,   801/ 1699; avg loss: 0.68; acc:  76.38;    7758 s elapsed
Epoch  4,   851/ 1699; avg loss: 0.70; acc:  76.22;    7824 s elapsed
Epoch  4,   901/ 1699; avg loss: 0.64; acc:  77.78;    7890 s elapsed
Epoch  4,   951/ 1699; avg loss: 0.66; acc:  76.81;    7955 s elapsed
Epoch  4,  1001/ 1699; avg loss: 0.65; acc:  77.03;    8021 s elapsed
Epoch  4,  1051/ 1699; avg loss: 0.68; acc:  77.28;    8087 s elapsed
Epoch  4,  1101/ 1699; avg loss: 0.68; acc:  76.81;    8152 s elapsed
Epoch  4,  1151/ 1699; avg loss: 0.66; acc:  78.53;    8216 s elapsed
Epoch  4,  1201/ 1699; avg loss: 0.70; acc:  75.53;    8281 s elapsed
Epoch  4,  1251/ 1699; avg loss: 0.71; acc:  75.94;    8347 s elapsed
Epoch  4,  1301/ 1699; avg loss: 0.70; acc:  75.97;    8413 s elapsed
Epoch  4,  1351/ 1699; avg loss: 0.67; acc:  76.41;    8479 s elapsed
Epoch  4,  1401/ 1699; avg loss: 0.69; acc:  75.75;    8544 s elapsed
Epoch  4,  1451/ 1699; avg loss: 0.67; acc:  77.53;    8608 s elapsed
Epoch  4,  1501/ 1699; avg loss: 0.70; acc:  76.31;    8674 s elapsed
Epoch  4,  1551/ 1699; avg loss: 0.71; acc:  75.56;    8739 s elapsed
Epoch  4,  1601/ 1699; avg loss: 0.69; acc:  75.56;    8805 s elapsed
Epoch  4,  1651/ 1699; avg loss: 0.66; acc:  76.56;    8859 s elapsed
Epoch 4:	 average loss: 0.66	 train accuracy: 77.0371
====================
Evaluating on validation set:
Validation loss: 1.22
Validation accuracy: 67.05
====================

Epoch  5,     1/ 1699; avg loss: 0.58; acc:  81.25;    8946 s elapsed
Epoch  5,    51/ 1699; avg loss: 0.57; acc:  79.88;    9011 s elapsed
Epoch  5,   101/ 1699; avg loss: 0.57; acc:  79.81;    9077 s elapsed
Epoch  5,   151/ 1699; avg loss: 0.60; acc:  78.78;    9143 s elapsed
Epoch  5,   201/ 1699; avg loss: 0.59; acc:  79.62;    9207 s elapsed
Epoch  5,   251/ 1699; avg loss: 0.60; acc:  79.34;    9272 s elapsed
Epoch  5,   301/ 1699; avg loss: 0.57; acc:  79.44;    9338 s elapsed
Epoch  5,   351/ 1699; avg loss: 0.61; acc:  78.72;    9402 s elapsed
Epoch  5,   401/ 1699; avg loss: 0.62; acc:  78.16;    9468 s elapsed
Epoch  5,   451/ 1699; avg loss: 0.61; acc:  79.03;    9534 s elapsed
Epoch  5,   501/ 1699; avg loss: 0.62; acc:  78.19;    9599 s elapsed
Epoch  5,   551/ 1699; avg loss: 0.61; acc:  77.69;    9664 s elapsed
Epoch  5,   601/ 1699; avg loss: 0.61; acc:  78.91;    9728 s elapsed
Epoch  5,   651/ 1699; avg loss: 0.64; acc:  77.59;    9794 s elapsed
Epoch  5,   701/ 1699; avg loss: 0.61; acc:  78.03;    9859 s elapsed
Epoch  5,   751/ 1699; avg loss: 0.61; acc:  77.78;    9923 s elapsed
Epoch  5,   801/ 1699; avg loss: 0.63; acc:  77.97;    9988 s elapsed
Epoch  5,   851/ 1699; avg loss: 0.65; acc:  77.59;   10053 s elapsed
Epoch  5,   901/ 1699; avg loss: 0.66; acc:  77.50;   10119 s elapsed
Epoch  5,   951/ 1699; avg loss: 0.62; acc:  78.19;   10185 s elapsed
Epoch  5,  1001/ 1699; avg loss: 0.65; acc:  77.81;   10250 s elapsed
Epoch  5,  1051/ 1699; avg loss: 0.64; acc:  78.41;   10316 s elapsed
Epoch  5,  1101/ 1699; avg loss: 0.68; acc:  76.88;   10382 s elapsed
Epoch  5,  1151/ 1699; avg loss: 0.64; acc:  77.47;   10448 s elapsed
Epoch  5,  1201/ 1699; avg loss: 0.65; acc:  77.50;   10513 s elapsed
Epoch  5,  1251/ 1699; avg loss: 0.64; acc:  78.62;   10579 s elapsed
Epoch  5,  1301/ 1699; avg loss: 0.64; acc:  78.22;   10644 s elapsed
Epoch  5,  1351/ 1699; avg loss: 0.66; acc:  76.53;   10710 s elapsed
Epoch  5,  1401/ 1699; avg loss: 0.69; acc:  76.66;   10775 s elapsed
Epoch  5,  1451/ 1699; avg loss: 0.68; acc:  76.62;   10840 s elapsed
Epoch  5,  1501/ 1699; avg loss: 0.65; acc:  76.66;   10906 s elapsed
Epoch  5,  1551/ 1699; avg loss: 0.68; acc:  76.16;   10971 s elapsed
Epoch  5,  1601/ 1699; avg loss: 0.67; acc:  77.75;   11037 s elapsed
Epoch  5,  1651/ 1699; avg loss: 0.68; acc:  76.91;   11092 s elapsed
Epoch 5:	 average loss: 0.63	 train accuracy: 77.9882
====================
Evaluating on validation set:
Validation loss: 1.17
Validation accuracy: 68.6
====================

Epoch  6,     1/ 1699; avg loss: 0.48; acc:  82.81;   11178 s elapsed
Epoch  6,    51/ 1699; avg loss: 0.55; acc:  81.59;   11245 s elapsed
Epoch  6,   101/ 1699; avg loss: 0.57; acc:  79.66;   11310 s elapsed
Epoch  6,   151/ 1699; avg loss: 0.53; acc:  80.78;   11376 s elapsed
Epoch  6,   201/ 1699; avg loss: 0.54; acc:  81.47;   11440 s elapsed
Epoch  6,   251/ 1699; avg loss: 0.57; acc:  81.25;   11505 s elapsed
Epoch  6,   301/ 1699; avg loss: 0.59; acc:  79.53;   11571 s elapsed
Epoch  6,   351/ 1699; avg loss: 0.56; acc:  80.81;   11637 s elapsed
Epoch  6,   401/ 1699; avg loss: 0.57; acc:  79.62;   11703 s elapsed
Epoch  6,   451/ 1699; avg loss: 0.58; acc:  79.16;   11768 s elapsed
Epoch  6,   501/ 1699; avg loss: 0.57; acc:  80.91;   11833 s elapsed
Epoch  6,   551/ 1699; avg loss: 0.60; acc:  79.53;   11899 s elapsed
Epoch  6,   601/ 1699; avg loss: 0.61; acc:  79.62;   11964 s elapsed
Epoch  6,   651/ 1699; avg loss: 0.57; acc:  79.56;   12030 s elapsed
Epoch  6,   701/ 1699; avg loss: 0.58; acc:  79.75;   12096 s elapsed
Epoch  6,   751/ 1699; avg loss: 0.60; acc:  78.62;   12160 s elapsed
Epoch  6,   801/ 1699; avg loss: 0.61; acc:  79.47;   12225 s elapsed
Epoch  6,   851/ 1699; avg loss: 0.59; acc:  78.56;   12290 s elapsed
Epoch  6,   901/ 1699; avg loss: 0.64; acc:  77.28;   12356 s elapsed
Epoch  6,   951/ 1699; avg loss: 0.60; acc:  78.78;   12421 s elapsed
Epoch  6,  1001/ 1699; avg loss: 0.62; acc:  78.28;   12486 s elapsed
Epoch  6,  1051/ 1699; avg loss: 0.64; acc:  78.19;   12551 s elapsed
Epoch  6,  1101/ 1699; avg loss: 0.62; acc:  77.69;   12617 s elapsed
Epoch  6,  1151/ 1699; avg loss: 0.61; acc:  78.09;   12682 s elapsed
Epoch  6,  1201/ 1699; avg loss: 0.62; acc:  78.16;   12748 s elapsed
Epoch  6,  1251/ 1699; avg loss: 0.63; acc:  77.34;   12813 s elapsed
Epoch  6,  1301/ 1699; avg loss: 0.64; acc:  76.66;   12878 s elapsed
Epoch  6,  1351/ 1699; avg loss: 0.63; acc:  78.03;   12944 s elapsed
Epoch  6,  1401/ 1699; avg loss: 0.64; acc:  77.50;   13010 s elapsed
Epoch  6,  1451/ 1699; avg loss: 0.64; acc:  77.53;   13074 s elapsed
Epoch  6,  1501/ 1699; avg loss: 0.64; acc:  77.22;   13140 s elapsed
Epoch  6,  1551/ 1699; avg loss: 0.63; acc:  77.59;   13205 s elapsed
Epoch  6,  1601/ 1699; avg loss: 0.67; acc:  76.31;   13271 s elapsed
Epoch  6,  1651/ 1699; avg loss: 0.64; acc:  77.09;   13326 s elapsed
Epoch 6:	 average loss: 0.60	 train accuracy: 78.7976
====================
Evaluating on validation set:
Validation loss: 1.14
Validation accuracy: 69.3
====================

Epoch  7,     1/ 1699; avg loss: 0.48; acc:  82.81;   13413 s elapsed
Epoch  7,    51/ 1699; avg loss: 0.50; acc:  82.31;   13479 s elapsed
Epoch  7,   101/ 1699; avg loss: 0.50; acc:  81.50;   13544 s elapsed
Epoch  7,   151/ 1699; avg loss: 0.51; acc:  81.69;   13610 s elapsed
Epoch  7,   201/ 1699; avg loss: 0.53; acc:  81.91;   13677 s elapsed
Epoch  7,   251/ 1699; avg loss: 0.54; acc:  81.19;   13743 s elapsed
Epoch  7,   301/ 1699; avg loss: 0.53; acc:  81.53;   13808 s elapsed
Epoch  7,   351/ 1699; avg loss: 0.55; acc:  81.56;   13874 s elapsed
Epoch  7,   401/ 1699; avg loss: 0.55; acc:  81.38;   13940 s elapsed
Epoch  7,   451/ 1699; avg loss: 0.55; acc:  80.84;   14005 s elapsed
Epoch  7,   501/ 1699; avg loss: 0.57; acc:  79.94;   14071 s elapsed
Epoch  7,   551/ 1699; avg loss: 0.55; acc:  80.53;   14136 s elapsed
Epoch  7,   601/ 1699; avg loss: 0.60; acc:  78.59;   14201 s elapsed
Epoch  7,   651/ 1699; avg loss: 0.56; acc:  79.84;   14267 s elapsed
Epoch  7,   701/ 1699; avg loss: 0.59; acc:  78.78;   14331 s elapsed
Epoch  7,   751/ 1699; avg loss: 0.58; acc:  79.41;   14397 s elapsed
Epoch  7,   801/ 1699; avg loss: 0.57; acc:  80.09;   14462 s elapsed
Epoch  7,   851/ 1699; avg loss: 0.61; acc:  79.03;   14528 s elapsed
Epoch  7,   901/ 1699; avg loss: 0.58; acc:  80.59;   14593 s elapsed
Epoch  7,   951/ 1699; avg loss: 0.58; acc:  79.75;   14658 s elapsed
Epoch  7,  1001/ 1699; avg loss: 0.58; acc:  79.72;   14724 s elapsed
Epoch  7,  1051/ 1699; avg loss: 0.59; acc:  79.09;   14789 s elapsed
Epoch  7,  1101/ 1699; avg loss: 0.60; acc:  78.97;   14854 s elapsed
Epoch  7,  1151/ 1699; avg loss: 0.57; acc:  79.53;   14919 s elapsed
Epoch  7,  1201/ 1699; avg loss: 0.55; acc:  80.84;   14986 s elapsed
Epoch  7,  1251/ 1699; avg loss: 0.62; acc:  77.00;   15051 s elapsed
Epoch  7,  1301/ 1699; avg loss: 0.58; acc:  80.12;   15117 s elapsed
Epoch  7,  1351/ 1699; avg loss: 0.63; acc:  76.88;   15182 s elapsed
Epoch  7,  1401/ 1699; avg loss: 0.63; acc:  78.16;   15248 s elapsed
Epoch  7,  1451/ 1699; avg loss: 0.62; acc:  77.81;   15313 s elapsed
Epoch  7,  1501/ 1699; avg loss: 0.63; acc:  79.25;   15379 s elapsed
Epoch  7,  1551/ 1699; avg loss: 0.61; acc:  79.69;   15444 s elapsed
Epoch  7,  1601/ 1699; avg loss: 0.62; acc:  79.19;   15509 s elapsed
Epoch  7,  1651/ 1699; avg loss: 0.61; acc:  78.34;   15563 s elapsed
Epoch 7:	 average loss: 0.58	 train accuracy: 79.7883
====================
Evaluating on validation set:
Validation loss: 1.15
Validation accuracy: 68.5
====================

Epoch  8,     1/ 1699; avg loss: 0.42; acc:  82.81;   15650 s elapsed
Epoch  8,    51/ 1699; avg loss: 0.49; acc:  82.69;   15715 s elapsed
Epoch  8,   101/ 1699; avg loss: 0.47; acc:  84.22;   15781 s elapsed
Epoch  8,   151/ 1699; avg loss: 0.47; acc:  83.88;   15846 s elapsed
Epoch  8,   201/ 1699; avg loss: 0.49; acc:  83.62;   15912 s elapsed
Epoch  8,   251/ 1699; avg loss: 0.50; acc:  82.94;   15978 s elapsed
Epoch  8,   301/ 1699; avg loss: 0.48; acc:  83.41;   16043 s elapsed
Epoch  8,   351/ 1699; avg loss: 0.52; acc:  82.31;   16108 s elapsed
Epoch  8,   401/ 1699; avg loss: 0.51; acc:  82.16;   16174 s elapsed
Epoch  8,   451/ 1699; avg loss: 0.53; acc:  82.12;   16238 s elapsed
Epoch  8,   501/ 1699; avg loss: 0.53; acc:  80.97;   16304 s elapsed
Epoch  8,   551/ 1699; avg loss: 0.53; acc:  81.91;   16369 s elapsed
Epoch  8,   601/ 1699; avg loss: 0.54; acc:  80.75;   16434 s elapsed
Epoch  8,   651/ 1699; avg loss: 0.54; acc:  81.12;   16498 s elapsed
Epoch  8,   701/ 1699; avg loss: 0.55; acc:  80.44;   16564 s elapsed
Epoch  8,   751/ 1699; avg loss: 0.55; acc:  80.62;   16631 s elapsed
Epoch  8,   801/ 1699; avg loss: 0.57; acc:  79.81;   16697 s elapsed
Epoch  8,   851/ 1699; avg loss: 0.56; acc:  79.44;   16764 s elapsed
Epoch  8,   901/ 1699; avg loss: 0.59; acc:  79.53;   16829 s elapsed
Epoch  8,   951/ 1699; avg loss: 0.59; acc:  80.94;   16896 s elapsed
Epoch  8,  1001/ 1699; avg loss: 0.58; acc:  80.06;   16962 s elapsed
Epoch  8,  1051/ 1699; avg loss: 0.59; acc:  79.47;   17028 s elapsed
Epoch  8,  1101/ 1699; avg loss: 0.59; acc:  79.69;   17093 s elapsed
Epoch  8,  1151/ 1699; avg loss: 0.58; acc:  79.72;   17160 s elapsed
Epoch  8,  1201/ 1699; avg loss: 0.58; acc:  80.41;   17226 s elapsed
Epoch  8,  1251/ 1699; avg loss: 0.58; acc:  79.38;   17291 s elapsed
Epoch  8,  1301/ 1699; avg loss: 0.56; acc:  80.25;   17356 s elapsed
Epoch  8,  1351/ 1699; avg loss: 0.58; acc:  79.38;   17421 s elapsed
Epoch  8,  1401/ 1699; avg loss: 0.58; acc:  79.78;   17487 s elapsed
Epoch  8,  1451/ 1699; avg loss: 0.57; acc:  79.25;   17551 s elapsed
Epoch  8,  1501/ 1699; avg loss: 0.58; acc:  79.31;   17616 s elapsed
Epoch  8,  1551/ 1699; avg loss: 0.60; acc:  79.56;   17683 s elapsed
Epoch  8,  1601/ 1699; avg loss: 0.57; acc:  79.84;   17748 s elapsed
Epoch  8,  1651/ 1699; avg loss: 0.59; acc:  78.56;   17803 s elapsed
Epoch 8:	 average loss: 0.55	 train accuracy: 80.8102
====================
Evaluating on validation set:
Validation loss: 1.13
Validation accuracy: 70.25
====================

Epoch  9,     1/ 1699; avg loss: 0.39; acc:  87.50;   17890 s elapsed
Epoch  9,    51/ 1699; avg loss: 0.45; acc:  84.94;   17954 s elapsed
Epoch  9,   101/ 1699; avg loss: 0.43; acc:  85.72;   18020 s elapsed
Epoch  9,   151/ 1699; avg loss: 0.45; acc:  84.94;   18086 s elapsed
Epoch  9,   201/ 1699; avg loss: 0.47; acc:  83.59;   18151 s elapsed
Epoch  9,   251/ 1699; avg loss: 0.46; acc:  84.03;   18217 s elapsed
Epoch  9,   301/ 1699; avg loss: 0.46; acc:  83.56;   18282 s elapsed
Epoch  9,   351/ 1699; avg loss: 0.49; acc:  83.06;   18348 s elapsed
Epoch  9,   401/ 1699; avg loss: 0.53; acc:  81.34;   18414 s elapsed
Epoch  9,   451/ 1699; avg loss: 0.48; acc:  83.19;   18479 s elapsed
Epoch  9,   501/ 1699; avg loss: 0.53; acc:  80.69;   18545 s elapsed
Epoch  9,   551/ 1699; avg loss: 0.51; acc:  81.94;   18610 s elapsed
Epoch  9,   601/ 1699; avg loss: 0.54; acc:  81.25;   18676 s elapsed
Epoch  9,   651/ 1699; avg loss: 0.52; acc:  80.84;   18742 s elapsed
Epoch  9,   701/ 1699; avg loss: 0.50; acc:  82.16;   18808 s elapsed
Epoch  9,   751/ 1699; avg loss: 0.52; acc:  82.00;   18873 s elapsed
Epoch  9,   801/ 1699; avg loss: 0.54; acc:  81.25;   18938 s elapsed
Epoch  9,   851/ 1699; avg loss: 0.50; acc:  82.41;   19004 s elapsed
Epoch  9,   901/ 1699; avg loss: 0.49; acc:  83.12;   19070 s elapsed
Epoch  9,   951/ 1699; avg loss: 0.55; acc:  81.09;   19136 s elapsed
Epoch  9,  1001/ 1699; avg loss: 0.53; acc:  81.66;   19200 s elapsed
Epoch  9,  1051/ 1699; avg loss: 0.56; acc:  81.06;   19266 s elapsed
Epoch  9,  1101/ 1699; avg loss: 0.54; acc:  80.91;   19332 s elapsed
Epoch  9,  1151/ 1699; avg loss: 0.55; acc:  81.06;   19398 s elapsed
Epoch  9,  1201/ 1699; avg loss: 0.54; acc:  81.25;   19463 s elapsed
Epoch  9,  1251/ 1699; avg loss: 0.57; acc:  80.41;   19530 s elapsed
Epoch  9,  1301/ 1699; avg loss: 0.57; acc:  80.28;   19596 s elapsed
Epoch  9,  1351/ 1699; avg loss: 0.58; acc:  79.56;   19663 s elapsed
Epoch  9,  1401/ 1699; avg loss: 0.56; acc:  80.38;   19728 s elapsed
Epoch  9,  1451/ 1699; avg loss: 0.58; acc:  80.25;   19794 s elapsed
Epoch  9,  1501/ 1699; avg loss: 0.59; acc:  79.16;   19860 s elapsed
Epoch  9,  1551/ 1699; avg loss: 0.57; acc:  79.59;   19925 s elapsed
Epoch  9,  1601/ 1699; avg loss: 0.58; acc:  79.66;   19990 s elapsed
Epoch  9,  1651/ 1699; avg loss: 0.56; acc:  79.88;   20045 s elapsed
Epoch 9:	 average loss: 0.53	 train accuracy: 81.6858
====================
Evaluating on validation set:
Validation loss: 1.19
Validation accuracy: 69.1
====================

Epoch 10,     1/ 1699; avg loss: 0.31; acc:  93.75;   20130 s elapsed
Epoch 10,    51/ 1699; avg loss: 0.42; acc:  85.19;   20196 s elapsed
Epoch 10,   101/ 1699; avg loss: 0.45; acc:  84.53;   20261 s elapsed
Epoch 10,   151/ 1699; avg loss: 0.42; acc:  85.31;   20327 s elapsed
Epoch 10,   201/ 1699; avg loss: 0.44; acc:  84.41;   20391 s elapsed
Epoch 10,   251/ 1699; avg loss: 0.44; acc:  84.25;   20458 s elapsed
Epoch 10,   301/ 1699; avg loss: 0.45; acc:  84.66;   20523 s elapsed
Epoch 10,   351/ 1699; avg loss: 0.45; acc:  84.00;   20587 s elapsed
Epoch 10,   401/ 1699; avg loss: 0.48; acc:  83.03;   20653 s elapsed
Epoch 10,   451/ 1699; avg loss: 0.47; acc:  83.81;   20719 s elapsed
Epoch 10,   501/ 1699; avg loss: 0.48; acc:  83.81;   20784 s elapsed
Epoch 10,   551/ 1699; avg loss: 0.48; acc:  82.97;   20849 s elapsed
Epoch 10,   601/ 1699; avg loss: 0.49; acc:  82.62;   20914 s elapsed
Epoch 10,   651/ 1699; avg loss: 0.47; acc:  83.62;   20981 s elapsed
Epoch 10,   701/ 1699; avg loss: 0.52; acc:  82.34;   21047 s elapsed
Epoch 10,   751/ 1699; avg loss: 0.50; acc:  82.53;   21112 s elapsed
Epoch 10,   801/ 1699; avg loss: 0.48; acc:  82.97;   21179 s elapsed
Epoch 10,   851/ 1699; avg loss: 0.49; acc:  82.59;   21244 s elapsed
Epoch 10,   901/ 1699; avg loss: 0.52; acc:  81.50;   21308 s elapsed
Epoch 10,   951/ 1699; avg loss: 0.53; acc:  81.94;   21374 s elapsed
Epoch 10,  1001/ 1699; avg loss: 0.51; acc:  81.53;   21440 s elapsed
Epoch 10,  1051/ 1699; avg loss: 0.52; acc:  81.81;   21505 s elapsed
Epoch 10,  1101/ 1699; avg loss: 0.50; acc:  82.53;   21570 s elapsed
Epoch 10,  1151/ 1699; avg loss: 0.52; acc:  81.56;   21635 s elapsed
Epoch 10,  1201/ 1699; avg loss: 0.52; acc:  82.53;   21702 s elapsed
Epoch 10,  1251/ 1699; avg loss: 0.53; acc:  80.81;   21767 s elapsed
Epoch 10,  1301/ 1699; avg loss: 0.53; acc:  81.41;   21833 s elapsed
Epoch 10,  1351/ 1699; avg loss: 0.55; acc:  81.16;   21899 s elapsed
Epoch 10,  1401/ 1699; avg loss: 0.54; acc:  81.03;   21964 s elapsed
Epoch 10,  1451/ 1699; avg loss: 0.56; acc:  81.78;   22029 s elapsed
Epoch 10,  1501/ 1699; avg loss: 0.55; acc:  80.34;   22094 s elapsed
Epoch 10,  1551/ 1699; avg loss: 0.51; acc:  81.94;   22159 s elapsed
Epoch 10,  1601/ 1699; avg loss: 0.54; acc:  81.22;   22225 s elapsed
Epoch 10,  1651/ 1699; avg loss: 0.56; acc:  79.72;   22278 s elapsed
Epoch 10:	 average loss: 0.50	 train accuracy: 82.5421
====================
Evaluating on validation set:
Validation loss: 1.16
Validation accuracy: 68.65
====================
Namespace(batch_size=64, dict='data/CBTest/data/cbtest_NE_train.txtdict.pt', dropout=0.1, embed_size=384, epochs=50, gpu=0, gru_size=384, learning_rate=0.001, log_interval=50, save_model='model_simplegru', start_epoch=1, train_from='models/model2_epoch10_acc_68.65.pt', traindata='data/CBTest/data/cbtest_NE_train.txt.pt', validdata='data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt', weight_decay=0.0001)
('Loading dictrionary from ', 'data/CBTest/data/cbtest_NE_train.txtdict.pt')
('Loading train data from ', 'data/CBTest/data/cbtest_NE_train.txt.pt')
('Loading valid data from ', 'data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt')
 * vocabulary size = 15683
 * number of training samples. 108719
 * maximum batch size. 64
Building model...
Loading model from checkpoint at 
* number of parameters: 7796352
AoAReader(
  (embedding): Embedding(15683, 384, padding_idx=0)
  (gru): GRU(384, 384, batch_first=True, dropout=0.1, bidirectional=True)
)

Epoch 11,     1/ 1699; avg loss: 0.36; acc:  85.94;       1 s elapsed
Epoch 11,    51/ 1699; avg loss: 0.41; acc:  86.34;      32 s elapsed
Epoch 11,   101/ 1699; avg loss: 0.39; acc:  86.66;      63 s elapsed
Epoch 11,   151/ 1699; avg loss: 0.40; acc:  86.06;      93 s elapsed
Epoch 11,   201/ 1699; avg loss: 0.39; acc:  86.41;     125 s elapsed
Epoch 11,   251/ 1699; avg loss: 0.43; acc:  85.22;     157 s elapsed
Epoch 11,   301/ 1699; avg loss: 0.42; acc:  85.16;     188 s elapsed
Epoch 11,   351/ 1699; avg loss: 0.43; acc:  85.44;     219 s elapsed
Epoch 11,   401/ 1699; avg loss: 0.43; acc:  85.62;     250 s elapsed
Epoch 11,   451/ 1699; avg loss: 0.44; acc:  84.50;     282 s elapsed
Epoch 11,   501/ 1699; avg loss: 0.46; acc:  84.56;     312 s elapsed
Epoch 11,   551/ 1699; avg loss: 0.45; acc:  84.38;     344 s elapsed
Epoch 11,   601/ 1699; avg loss: 0.46; acc:  84.84;     375 s elapsed
Epoch 11,   651/ 1699; avg loss: 0.44; acc:  84.44;     406 s elapsed
Epoch 11,   701/ 1699; avg loss: 0.45; acc:  83.75;     436 s elapsed
Epoch 11,   751/ 1699; avg loss: 0.48; acc:  84.12;     468 s elapsed
Epoch 11,   801/ 1699; avg loss: 0.47; acc:  84.41;     500 s elapsed
Epoch 11,   851/ 1699; avg loss: 0.49; acc:  82.91;     530 s elapsed
Epoch 11,   901/ 1699; avg loss: 0.48; acc:  83.56;     561 s elapsed
Epoch 11,   951/ 1699; avg loss: 0.49; acc:  82.47;     592 s elapsed
Epoch 11,  1001/ 1699; avg loss: 0.46; acc:  83.72;     623 s elapsed
Epoch 11,  1051/ 1699; avg loss: 0.50; acc:  82.22;     654 s elapsed
Epoch 11,  1101/ 1699; avg loss: 0.49; acc:  83.09;     684 s elapsed
Epoch 11,  1151/ 1699; avg loss: 0.48; acc:  83.50;     716 s elapsed
Epoch 11,  1201/ 1699; avg loss: 0.51; acc:  82.09;     747 s elapsed
Epoch 11,  1251/ 1699; avg loss: 0.51; acc:  81.97;     778 s elapsed
Epoch 11,  1301/ 1699; avg loss: 0.51; acc:  81.69;     810 s elapsed
Epoch 11,  1351/ 1699; avg loss: 0.51; acc:  81.53;     840 s elapsed
Epoch 11,  1401/ 1699; avg loss: 0.51; acc:  81.91;     872 s elapsed
Epoch 11,  1451/ 1699; avg loss: 0.50; acc:  81.75;     902 s elapsed
Epoch 11,  1501/ 1699; avg loss: 0.52; acc:  81.78;     932 s elapsed
Epoch 11,  1551/ 1699; avg loss: 0.54; acc:  81.03;     962 s elapsed
Epoch 11,  1601/ 1699; avg loss: 0.53; acc:  81.16;     993 s elapsed
Epoch 11,  1651/ 1699; avg loss: 0.53; acc:  81.69;    1025 s elapsed
Epoch 11:	 average loss: 0.47	 train accuracy: 83.5751
====================
Evaluating on validation set:
Validation loss: 1.19
Validation accuracy: 69.75
====================

Epoch 12,     1/ 1699; avg loss: 0.39; acc:  81.25;    1060 s elapsed
Epoch 12,    51/ 1699; avg loss: 0.36; acc:  87.84;    1092 s elapsed
Epoch 12,   101/ 1699; avg loss: 0.36; acc:  88.00;    1123 s elapsed
Epoch 12,   151/ 1699; avg loss: 0.39; acc:  87.00;    1154 s elapsed
Epoch 12,   201/ 1699; avg loss: 0.37; acc:  87.44;    1184 s elapsed
Epoch 12,   251/ 1699; avg loss: 0.38; acc:  87.50;    1215 s elapsed
Epoch 12,   301/ 1699; avg loss: 0.40; acc:  86.38;    1245 s elapsed
Epoch 12,   351/ 1699; avg loss: 0.39; acc:  86.94;    1275 s elapsed
Epoch 12,   401/ 1699; avg loss: 0.38; acc:  87.25;    1307 s elapsed
Epoch 12,   451/ 1699; avg loss: 0.42; acc:  86.03;    1337 s elapsed
Epoch 12,   501/ 1699; avg loss: 0.40; acc:  86.06;    1368 s elapsed
Epoch 12,   551/ 1699; avg loss: 0.42; acc:  85.62;    1398 s elapsed
Epoch 12,   601/ 1699; avg loss: 0.43; acc:  85.06;    1429 s elapsed
Epoch 12,   651/ 1699; avg loss: 0.42; acc:  85.66;    1459 s elapsed
Epoch 12,   701/ 1699; avg loss: 0.47; acc:  84.47;    1491 s elapsed
Epoch 12,   751/ 1699; avg loss: 0.42; acc:  85.50;    1522 s elapsed
Epoch 12,   801/ 1699; avg loss: 0.44; acc:  85.59;    1552 s elapsed
Epoch 12,   851/ 1699; avg loss: 0.44; acc:  85.12;    1583 s elapsed
Epoch 12,   901/ 1699; avg loss: 0.48; acc:  82.25;    1613 s elapsed
Epoch 12,   951/ 1699; avg loss: 0.49; acc:  83.47;    1644 s elapsed
Epoch 12,  1001/ 1699; avg loss: 0.45; acc:  84.53;    1674 s elapsed
Epoch 12,  1051/ 1699; avg loss: 0.48; acc:  82.97;    1705 s elapsed
Epoch 12,  1101/ 1699; avg loss: 0.47; acc:  83.19;    1736 s elapsed
Epoch 12,  1151/ 1699; avg loss: 0.47; acc:  83.53;    1767 s elapsed
Epoch 12,  1201/ 1699; avg loss: 0.47; acc:  84.53;    1798 s elapsed
Epoch 12,  1251/ 1699; avg loss: 0.46; acc:  84.19;    1829 s elapsed
Epoch 12,  1301/ 1699; avg loss: 0.48; acc:  83.56;    1860 s elapsed
Epoch 12,  1351/ 1699; avg loss: 0.49; acc:  82.22;    1891 s elapsed
Epoch 12,  1401/ 1699; avg loss: 0.51; acc:  82.31;    1921 s elapsed
Epoch 12,  1451/ 1699; avg loss: 0.50; acc:  82.78;    1952 s elapsed
Epoch 12,  1501/ 1699; avg loss: 0.53; acc:  82.22;    1983 s elapsed
Epoch 12,  1551/ 1699; avg loss: 0.52; acc:  82.09;    2014 s elapsed
Epoch 12,  1601/ 1699; avg loss: 0.49; acc:  83.19;    2045 s elapsed
Epoch 12,  1651/ 1699; avg loss: 0.52; acc:  82.25;    2075 s elapsed
Epoch 12:	 average loss: 0.45	 train accuracy: 84.7331
====================
Evaluating on validation set:
Validation loss: 1.17
Validation accuracy: 69.25
====================

Epoch 13,     1/ 1699; avg loss: 0.32; acc:  89.06;    2112 s elapsed
Epoch 13,    51/ 1699; avg loss: 0.33; acc:  89.28;    2143 s elapsed
Epoch 13,   101/ 1699; avg loss: 0.32; acc:  89.09;    2173 s elapsed
Epoch 13,   151/ 1699; avg loss: 0.35; acc:  88.59;    2204 s elapsed
Epoch 13,   201/ 1699; avg loss: 0.34; acc:  87.88;    2236 s elapsed
Epoch 13,   251/ 1699; avg loss: 0.33; acc:  89.06;    2267 s elapsed
Epoch 13,   301/ 1699; avg loss: 0.34; acc:  88.75;    2297 s elapsed
Epoch 13,   351/ 1699; avg loss: 0.36; acc:  88.22;    2329 s elapsed
Epoch 13,   401/ 1699; avg loss: 0.37; acc:  87.34;    2360 s elapsed
Epoch 13,   451/ 1699; avg loss: 0.38; acc:  87.12;    2390 s elapsed
Epoch 13,   501/ 1699; avg loss: 0.40; acc:  86.38;    2421 s elapsed
Epoch 13,   551/ 1699; avg loss: 0.41; acc:  86.00;    2452 s elapsed
Epoch 13,   601/ 1699; avg loss: 0.40; acc:  85.75;    2483 s elapsed
Epoch 13,   651/ 1699; avg loss: 0.42; acc:  86.25;    2513 s elapsed
Epoch 13,   701/ 1699; avg loss: 0.42; acc:  85.50;    2545 s elapsed
Epoch 13,   751/ 1699; avg loss: 0.43; acc:  85.31;    2576 s elapsed
Epoch 13,   801/ 1699; avg loss: 0.44; acc:  85.00;    2607 s elapsed
Epoch 13,   851/ 1699; avg loss: 0.41; acc:  85.69;    2638 s elapsed
Epoch 13,   901/ 1699; avg loss: 0.43; acc:  85.81;    2669 s elapsed
Epoch 13,   951/ 1699; avg loss: 0.45; acc:  84.53;    2700 s elapsed
Epoch 13,  1001/ 1699; avg loss: 0.43; acc:  84.34;    2731 s elapsed
Epoch 13,  1051/ 1699; avg loss: 0.44; acc:  84.53;    2762 s elapsed
Epoch 13,  1101/ 1699; avg loss: 0.45; acc:  84.94;    2792 s elapsed
Epoch 13,  1151/ 1699; avg loss: 0.43; acc:  84.12;    2823 s elapsed
Epoch 13,  1201/ 1699; avg loss: 0.44; acc:  84.59;    2854 s elapsed
Epoch 13,  1251/ 1699; avg loss: 0.44; acc:  84.94;    2884 s elapsed
Epoch 13,  1301/ 1699; avg loss: 0.48; acc:  83.81;    2915 s elapsed
Epoch 13,  1351/ 1699; avg loss: 0.45; acc:  84.78;    2946 s elapsed
Epoch 13,  1401/ 1699; avg loss: 0.49; acc:  84.22;    2977 s elapsed
Epoch 13,  1451/ 1699; avg loss: 0.48; acc:  83.03;    3008 s elapsed
Epoch 13,  1501/ 1699; avg loss: 0.45; acc:  83.75;    3038 s elapsed
Epoch 13,  1551/ 1699; avg loss: 0.49; acc:  82.44;    3068 s elapsed
Epoch 13,  1601/ 1699; avg loss: 0.47; acc:  83.72;    3099 s elapsed
Epoch 13,  1651/ 1699; avg loss: 0.47; acc:  83.19;    3129 s elapsed
Epoch 13:	 average loss: 0.42	 train accuracy: 85.6382
====================
Evaluating on validation set:
Validation loss: 1.25
Validation accuracy: 67.85
====================

Epoch 14,     1/ 1699; avg loss: 0.50; acc:  89.06;    3165 s elapsed
Epoch 14,    51/ 1699; avg loss: 0.31; acc:  89.75;    3197 s elapsed
Epoch 14,   101/ 1699; avg loss: 0.31; acc:  89.81;    3228 s elapsed
Epoch 14,   151/ 1699; avg loss: 0.31; acc:  89.81;    3259 s elapsed
Epoch 14,   201/ 1699; avg loss: 0.33; acc:  89.25;    3289 s elapsed
Epoch 14,   251/ 1699; avg loss: 0.33; acc:  88.72;    3320 s elapsed
Epoch 14,   301/ 1699; avg loss: 0.32; acc:  89.50;    3350 s elapsed
Epoch 14,   351/ 1699; avg loss: 0.33; acc:  88.88;    3381 s elapsed
Epoch 14,   401/ 1699; avg loss: 0.64; acc:  82.03;    3411 s elapsed
Epoch 14,   451/ 1699; avg loss: 0.47; acc:  84.09;    3441 s elapsed
Epoch 14,   501/ 1699; avg loss: 0.41; acc:  86.44;    3472 s elapsed
Epoch 14,   551/ 1699; avg loss: 0.43; acc:  85.66;    3503 s elapsed
Epoch 14,   601/ 1699; avg loss: 0.42; acc:  85.41;    3534 s elapsed
Epoch 14,   651/ 1699; avg loss: 0.41; acc:  85.53;    3565 s elapsed
Epoch 14,   701/ 1699; avg loss: 0.39; acc:  86.47;    3596 s elapsed
Epoch 14,   751/ 1699; avg loss: 0.43; acc:  85.38;    3627 s elapsed
Epoch 14,   801/ 1699; avg loss: 0.43; acc:  85.25;    3658 s elapsed
Epoch 14,   851/ 1699; avg loss: 0.44; acc:  85.06;    3688 s elapsed
Epoch 14,   901/ 1699; avg loss: 0.44; acc:  84.94;    3719 s elapsed
Epoch 14,   951/ 1699; avg loss: 0.43; acc:  85.50;    3750 s elapsed
Epoch 14,  1001/ 1699; avg loss: 0.45; acc:  84.34;    3781 s elapsed
Epoch 14,  1051/ 1699; avg loss: 0.44; acc:  84.59;    3812 s elapsed
Epoch 14,  1101/ 1699; avg loss: 0.43; acc:  85.38;    3843 s elapsed
Epoch 14,  1151/ 1699; avg loss: 0.44; acc:  84.81;    3874 s elapsed
Epoch 14,  1201/ 1699; avg loss: 0.43; acc:  85.25;    3904 s elapsed
Epoch 14,  1251/ 1699; avg loss: 0.45; acc:  83.97;    3935 s elapsed
Epoch 14,  1301/ 1699; avg loss: 0.45; acc:  84.72;    3967 s elapsed
Epoch 14,  1351/ 1699; avg loss: 0.45; acc:  84.53;    3998 s elapsed
Epoch 14,  1401/ 1699; avg loss: 0.47; acc:  84.78;    4029 s elapsed
Epoch 14,  1451/ 1699; avg loss: 0.44; acc:  84.69;    4060 s elapsed
Epoch 14,  1501/ 1699; avg loss: 0.46; acc:  83.44;    4091 s elapsed
Epoch 14,  1551/ 1699; avg loss: 0.46; acc:  84.75;    4121 s elapsed
Epoch 14,  1601/ 1699; avg loss: 0.45; acc:  84.19;    4152 s elapsed
Epoch 14,  1651/ 1699; avg loss: 0.46; acc:  84.34;    4182 s elapsed
Epoch 14:	 average loss: 0.42	 train accuracy: 85.7201
====================
Evaluating on validation set:
Validation loss: 1.27
Validation accuracy: 68.35
====================

Epoch 15,     1/ 1699; avg loss: 0.37; acc:  85.94;    4218 s elapsed
Epoch 15,    51/ 1699; avg loss: 0.29; acc:  90.34;    4249 s elapsed
Epoch 15,   101/ 1699; avg loss: 0.31; acc:  90.28;    4279 s elapsed
Epoch 15,   151/ 1699; avg loss: 0.32; acc:  89.88;    4310 s elapsed
Epoch 15,   201/ 1699; avg loss: 0.29; acc:  90.75;    4340 s elapsed
Epoch 15,   251/ 1699; avg loss: 0.30; acc:  89.91;    4372 s elapsed
Epoch 15,   301/ 1699; avg loss: 0.30; acc:  90.88;    4403 s elapsed
Epoch 15,   351/ 1699; avg loss: 0.32; acc:  89.25;    4433 s elapsed
Epoch 15,   401/ 1699; avg loss: 0.33; acc:  89.31;    4465 s elapsed
Epoch 15,   451/ 1699; avg loss: 0.33; acc:  88.88;    4495 s elapsed
Epoch 15,   501/ 1699; avg loss: 0.33; acc:  88.62;    4526 s elapsed
Epoch 15,   551/ 1699; avg loss: 0.35; acc:  88.47;    4556 s elapsed
Epoch 15,   601/ 1699; avg loss: 0.35; acc:  88.16;    4587 s elapsed
Epoch 15,   651/ 1699; avg loss: 0.36; acc:  87.09;    4618 s elapsed
Epoch 15,   701/ 1699; avg loss: 0.37; acc:  87.53;    4648 s elapsed
Epoch 15,   751/ 1699; avg loss: 0.37; acc:  87.06;    4679 s elapsed
Epoch 15,   801/ 1699; avg loss: 0.40; acc:  87.16;    4710 s elapsed
Epoch 15,   851/ 1699; avg loss: 0.37; acc:  87.09;    4741 s elapsed
Epoch 15,   901/ 1699; avg loss: 0.39; acc:  87.16;    4772 s elapsed
Epoch 15,   951/ 1699; avg loss: 0.39; acc:  86.66;    4803 s elapsed
Epoch 15,  1001/ 1699; avg loss: 0.40; acc:  86.34;    4835 s elapsed
Epoch 15,  1051/ 1699; avg loss: 0.39; acc:  86.59;    4866 s elapsed
Epoch 15,  1101/ 1699; avg loss: 0.41; acc:  85.34;    4897 s elapsed
Epoch 15,  1151/ 1699; avg loss: 0.41; acc:  86.22;    4927 s elapsed
Epoch 15,  1201/ 1699; avg loss: 0.40; acc:  85.97;    4958 s elapsed
Epoch 15,  1251/ 1699; avg loss: 0.41; acc:  86.78;    4989 s elapsed
Epoch 15,  1301/ 1699; avg loss: 0.43; acc:  85.53;    5020 s elapsed
Epoch 15,  1351/ 1699; avg loss: 0.43; acc:  84.75;    5050 s elapsed
Epoch 15,  1401/ 1699; avg loss: 0.41; acc:  86.19;    5082 s elapsed
Epoch 15,  1451/ 1699; avg loss: 0.42; acc:  86.12;    5113 s elapsed
Epoch 15,  1501/ 1699; avg loss: 0.44; acc:  85.12;    5143 s elapsed
Epoch 15,  1551/ 1699; avg loss: 0.43; acc:  85.38;    5174 s elapsed
Epoch 15,  1601/ 1699; avg loss: 0.44; acc:  84.53;    5204 s elapsed
Epoch 15,  1651/ 1699; avg loss: 0.42; acc:  85.22;    5235 s elapsed
Epoch 15:	 average loss: 0.37	 train accuracy: 87.3343
====================
Evaluating on validation set:
Validation loss: 1.21
Validation accuracy: 70.45
====================

Epoch 16,     1/ 1699; avg loss: 0.29; acc:  89.06;    5271 s elapsed
Epoch 16,    51/ 1699; avg loss: 0.26; acc:  91.50;    5302 s elapsed
Epoch 16,   101/ 1699; avg loss: 0.27; acc:  91.59;    5333 s elapsed
Epoch 16,   151/ 1699; avg loss: 0.28; acc:  90.69;    5364 s elapsed
Epoch 16,   201/ 1699; avg loss: 0.25; acc:  92.16;    5394 s elapsed
Epoch 16,   251/ 1699; avg loss: 0.27; acc:  91.12;    5425 s elapsed
Epoch 16,   301/ 1699; avg loss: 0.29; acc:  90.66;    5456 s elapsed
Epoch 16,   351/ 1699; avg loss: 0.28; acc:  90.97;    5487 s elapsed
Epoch 16,   401/ 1699; avg loss: 0.31; acc:  90.19;    5518 s elapsed
Epoch 16,   451/ 1699; avg loss: 0.32; acc:  89.38;    5549 s elapsed
Epoch 16,   501/ 1699; avg loss: 0.30; acc:  90.16;    5580 s elapsed
Epoch 16,   551/ 1699; avg loss: 0.32; acc:  89.38;    5611 s elapsed
Epoch 16,   601/ 1699; avg loss: 0.33; acc:  89.56;    5642 s elapsed
Epoch 16,   651/ 1699; avg loss: 0.31; acc:  89.31;    5673 s elapsed
Epoch 16,   701/ 1699; avg loss: 0.35; acc:  88.31;    5703 s elapsed
Epoch 16,   751/ 1699; avg loss: 0.34; acc:  87.81;    5733 s elapsed
Epoch 16,   801/ 1699; avg loss: 0.34; acc:  88.22;    5765 s elapsed
Epoch 16,   851/ 1699; avg loss: 0.35; acc:  87.94;    5796 s elapsed
Epoch 16,   901/ 1699; avg loss: 0.36; acc:  88.53;    5826 s elapsed
Epoch 16,   951/ 1699; avg loss: 0.35; acc:  88.53;    5857 s elapsed
Epoch 16,  1001/ 1699; avg loss: 0.35; acc:  87.97;    5887 s elapsed
Epoch 16,  1051/ 1699; avg loss: 0.37; acc:  87.19;    5918 s elapsed
Epoch 16,  1101/ 1699; avg loss: 0.38; acc:  87.31;    5949 s elapsed
Epoch 16,  1151/ 1699; avg loss: 0.41; acc:  84.78;    5979 s elapsed
Epoch 16,  1201/ 1699; avg loss: 0.40; acc:  86.75;    6010 s elapsed
Epoch 16,  1251/ 1699; avg loss: 0.39; acc:  87.00;    6040 s elapsed
Epoch 16,  1301/ 1699; avg loss: 0.39; acc:  86.53;    6072 s elapsed
Epoch 16,  1351/ 1699; avg loss: 0.37; acc:  87.31;    6103 s elapsed
Epoch 16,  1401/ 1699; avg loss: 0.41; acc:  86.03;    6134 s elapsed
Epoch 16,  1451/ 1699; avg loss: 0.39; acc:  87.44;    6165 s elapsed
Epoch 16,  1501/ 1699; avg loss: 0.42; acc:  86.12;    6196 s elapsed
Epoch 16,  1551/ 1699; avg loss: 0.42; acc:  86.00;    6226 s elapsed
Epoch 16,  1601/ 1699; avg loss: 0.38; acc:  87.00;    6258 s elapsed
Epoch 16,  1651/ 1699; avg loss: 0.43; acc:  85.72;    6288 s elapsed
Epoch 16:	 average loss: 0.35	 train accuracy: 88.3746
====================
Evaluating on validation set:
Validation loss: 1.32
Validation accuracy: 68.05
====================

Epoch 17,     1/ 1699; avg loss: 0.24; acc:  93.75;    6325 s elapsed
Epoch 17,    51/ 1699; avg loss: 0.25; acc:  91.94;    6355 s elapsed
Epoch 17,   101/ 1699; avg loss: 0.24; acc:  92.94;    6387 s elapsed
Epoch 17,   151/ 1699; avg loss: 0.25; acc:  92.31;    6418 s elapsed
Epoch 17,   201/ 1699; avg loss: 0.26; acc:  91.62;    6449 s elapsed
Epoch 17,   251/ 1699; avg loss: 0.25; acc:  92.06;    6479 s elapsed
Epoch 17,   301/ 1699; avg loss: 0.26; acc:  91.31;    6510 s elapsed
Epoch 17,   351/ 1699; avg loss: 0.26; acc:  91.31;    6541 s elapsed
Epoch 17,   401/ 1699; avg loss: 0.25; acc:  92.09;    6572 s elapsed
Epoch 17,   451/ 1699; avg loss: 0.28; acc:  91.16;    6603 s elapsed
Epoch 17,   501/ 1699; avg loss: 0.29; acc:  91.22;    6634 s elapsed
Epoch 17,   551/ 1699; avg loss: 0.30; acc:  90.88;    6665 s elapsed
Epoch 17,   601/ 1699; avg loss: 0.29; acc:  90.25;    6695 s elapsed
Epoch 17,   651/ 1699; avg loss: 0.31; acc:  90.06;    6726 s elapsed
Epoch 17,   701/ 1699; avg loss: 0.33; acc:  88.97;    6756 s elapsed
Epoch 17,   751/ 1699; avg loss: 0.31; acc:  90.22;    6787 s elapsed
Epoch 17,   801/ 1699; avg loss: 0.32; acc:  89.53;    6818 s elapsed
Epoch 17,   851/ 1699; avg loss: 0.33; acc:  88.91;    6849 s elapsed
Epoch 17,   901/ 1699; avg loss: 0.32; acc:  88.81;    6880 s elapsed
Epoch 17,   951/ 1699; avg loss: 0.32; acc:  89.12;    6912 s elapsed
Epoch 17,  1001/ 1699; avg loss: 0.36; acc:  87.25;    6943 s elapsed
Epoch 17,  1051/ 1699; avg loss: 0.33; acc:  89.00;    6973 s elapsed
Epoch 17,  1101/ 1699; avg loss: 0.36; acc:  87.97;    7004 s elapsed
Epoch 17,  1151/ 1699; avg loss: 0.37; acc:  87.25;    7035 s elapsed
Epoch 17,  1201/ 1699; avg loss: 0.36; acc:  87.25;    7065 s elapsed
Epoch 17,  1251/ 1699; avg loss: 0.37; acc:  88.03;    7096 s elapsed
Epoch 17,  1301/ 1699; avg loss: 0.40; acc:  86.84;    7127 s elapsed
Epoch 17,  1351/ 1699; avg loss: 0.35; acc:  88.41;    7158 s elapsed
Epoch 17,  1401/ 1699; avg loss: 0.36; acc:  87.84;    7188 s elapsed
Epoch 17,  1451/ 1699; avg loss: 0.38; acc:  86.75;    7219 s elapsed
Epoch 17,  1501/ 1699; avg loss: 0.40; acc:  86.47;    7250 s elapsed
Epoch 17,  1551/ 1699; avg loss: 0.39; acc:  86.94;    7281 s elapsed
Epoch 17,  1601/ 1699; avg loss: 0.40; acc:  86.25;    7311 s elapsed
Epoch 17,  1651/ 1699; avg loss: 0.41; acc:  86.47;    7342 s elapsed
Epoch 17:	 average loss: 0.32	 train accuracy: 89.2356
====================
Evaluating on validation set:
Validation loss: 1.36
Validation accuracy: 68.3
====================

Epoch 18,     1/ 1699; avg loss: 0.20; acc:  96.88;    7378 s elapsed
Epoch 18,    51/ 1699; avg loss: 0.24; acc:  92.66;    7408 s elapsed
run.sh: line 14: 30592 Terminated              python train.py -train_from models/$mf -traindata $d/cbtest_NE_train.txt.pt -validdata $d/cbtest_NE_valid_2000ex.txt.pt -dict $d/cbtest_NE_train.txtdict.pt -save_model $m -gru_size 384 -embed_size 384 -batch_size 64 -dropout 0.1 -epochs $epoch -learning_rate $lr -gpu 0 -log_interval 50
