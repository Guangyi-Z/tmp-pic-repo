  (embedding): Embedding(15683, 384, padding_idx=0)
  (gru): SimpleGRU(384, 384, batch_first=True, dropout=0.1, bidirectional=True)
)

Epoch  1,     1/ 1699; avg loss: 4.08; acc:  56.25;       3 s elapsed
Epoch  1,    51/ 1699; avg loss: 2.85; acc:  45.84;     147 s elapsed
Epoch  1,   101/ 1699; avg loss: 1.92; acc:  48.22;     289 s elapsed
Epoch  1,   151/ 1699; avg loss: 1.74; acc:  50.06;     432 s elapsed
Epoch  1,   201/ 1699; avg loss: 1.68; acc:  50.06;     570 s elapsed
Epoch  1,   251/ 1699; avg loss: 1.62; acc:  51.03;     714 s elapsed
Epoch  1,   301/ 1699; avg loss: 1.50; acc:  54.50;     855 s elapsed
Epoch  1,   351/ 1699; avg loss: 1.34; acc:  59.28;     995 s elapsed
Epoch  1,   401/ 1699; avg loss: 1.27; acc:  62.22;    1135 s elapsed
Epoch  1,   451/ 1699; avg loss: 1.17; acc:  62.88;    1280 s elapsed
Epoch  1,   501/ 1699; avg loss: 1.12; acc:  64.47;    1426 s elapsed
Epoch  1,   551/ 1699; avg loss: 1.10; acc:  64.97;    1570 s elapsed
Epoch  1,   601/ 1699; avg loss: 1.11; acc:  64.44;    1710 s elapsed
Epoch  1,   651/ 1699; avg loss: 1.06; acc:  66.56;    1851 s elapsed
Epoch  1,   701/ 1699; avg loss: 1.03; acc:  66.16;    1993 s elapsed
Epoch  1,   751/ 1699; avg loss: 1.00; acc:  67.88;    2137 s elapsed
Epoch  1,   801/ 1699; avg loss: 0.99; acc:  67.72;    2278 s elapsed
Epoch  1,   851/ 1699; avg loss: 1.01; acc:  66.81;    2423 s elapsed
Epoch  1,   901/ 1699; avg loss: 0.96; acc:  68.41;    2565 s elapsed
Epoch  1,   951/ 1699; avg loss: 0.97; acc:  68.38;    2708 s elapsed
Epoch  1,  1001/ 1699; avg loss: 0.95; acc:  68.06;    2849 s elapsed
Epoch  1,  1051/ 1699; avg loss: 0.92; acc:  69.84;    2991 s elapsed
Epoch  1,  1101/ 1699; avg loss: 0.94; acc:  69.62;    3136 s elapsed
Epoch  1,  1151/ 1699; avg loss: 0.93; acc:  69.41;    3276 s elapsed
Epoch  1,  1201/ 1699; avg loss: 0.91; acc:  70.81;    3416 s elapsed
Epoch  1,  1251/ 1699; avg loss: 0.93; acc:  70.53;    3556 s elapsed
Epoch  1,  1301/ 1699; avg loss: 0.88; acc:  71.97;    3700 s elapsed
Epoch  1,  1351/ 1699; avg loss: 0.89; acc:  70.31;    3843 s elapsed
Epoch  1,  1401/ 1699; avg loss: 0.95; acc:  69.00;    3983 s elapsed
Epoch  1,  1451/ 1699; avg loss: 0.90; acc:  70.56;    4122 s elapsed
Epoch  1,  1501/ 1699; avg loss: 0.85; acc:  71.03;    4265 s elapsed
Epoch  1,  1551/ 1699; avg loss: 0.85; acc:  72.91;    4409 s elapsed
Epoch  1,  1601/ 1699; avg loss: 0.88; acc:  71.16;    4550 s elapsed
Epoch  1,  1651/ 1699; avg loss: 0.89; acc:  70.41;    4695 s elapsed
Epoch 1:         average loss: 1.15      train accuracy: 64.8948
====================
Evaluating on validation set:
Validation loss: 1.29
Validation accuracy: 63.3
====================
Namespace(batch_size=64, dict='data/CBTest/data/cbtest_NE_train.txtdict.pt', dropout=0.1, embed_size=384, epochs=10, gpu=0, gru_size=384, learning_rate=0.001, log_interval=50, save_model='model_simplegru', start_epoch=1, train_from='models/model_simplegru_epoch1_acc_63.30.pt', traindata='data/CBTest/data/cbtest_NE_train.txt.pt', validdata='data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt', weight_decay=0.0001)
('Loading dictrionary from ', 'data/CBTest/data/cbtest_NE_train.txtdict.pt')
('Loading train data from ', 'data/CBTest/data/cbtest_NE_train.txt.pt')
('Loading valid data from ', 'data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt')
 * vocabulary size = 15683
 * number of training samples. 108719
 * maximum batch size. 64
Building model...
Loading model from checkpoint at
* number of parameters: 7796352
AoAReader(
  (embedding): Embedding(15683, 384, padding_idx=0)
  (gru): SimpleGRU(384, 384, batch_first=True, dropout=0.1, bidirectional=True)
)

Epoch  2,     1/ 1699; avg loss: 1.01; acc:  67.19;       4 s elapsed
Epoch  2,    51/ 1699; avg loss: 0.77; acc:  74.03;     143 s elapsed
Epoch  2,   101/ 1699; avg loss: 0.79; acc:  73.78;     286 s elapsed
Epoch  2,   151/ 1699; avg loss: 0.79; acc:  74.00;     428 s elapsed
Epoch  2,   201/ 1699; avg loss: 0.80; acc:  72.91;     573 s elapsed
Epoch  2,   251/ 1699; avg loss: 0.82; acc:  73.38;     716 s elapsed
Epoch  2,   301/ 1699; avg loss: 0.81; acc:  73.62;     857 s elapsed
Epoch  2,   351/ 1699; avg loss: 0.81; acc:  71.69;    1002 s elapsed
Epoch  2,   401/ 1699; avg loss: 0.79; acc:  73.09;    1149 s elapsed
Epoch  2,   451/ 1699; avg loss: 0.78; acc:  73.72;    1290 s elapsed
Epoch  2,   501/ 1699; avg loss: 0.81; acc:  73.09;    1433 s elapsed
Epoch  2,   551/ 1699; avg loss: 0.83; acc:  71.69;    1576 s elapsed
Epoch  2,   601/ 1699; avg loss: 0.77; acc:  73.75;    1718 s elapsed
Epoch  2,   651/ 1699; avg loss: 0.81; acc:  72.97;    1860 s elapsed
Epoch  2,   701/ 1699; avg loss: 0.80; acc:  73.44;    2005 s elapsed
Epoch  2,   751/ 1699; avg loss: 0.78; acc:  72.66;    2145 s elapsed
Epoch  2,   801/ 1699; avg loss: 0.79; acc:  74.28;    2290 s elapsed
Epoch  2,   851/ 1699; avg loss: 0.81; acc:  71.94;    2435 s elapsed
Epoch  2,   901/ 1699; avg loss: 0.80; acc:  73.06;    2578 s elapsed
Epoch  2,   951/ 1699; avg loss: 0.77; acc:  72.22;    2722 s elapsed
Epoch  2,  1001/ 1699; avg loss: 0.82; acc:  72.62;    2861 s elapsed
Epoch  2,  1051/ 1699; avg loss: 0.78; acc:  73.47;    3002 s elapsed
Epoch  2,  1101/ 1699; avg loss: 0.81; acc:  72.91;    3143 s elapsed
Epoch  2,  1151/ 1699; avg loss: 0.82; acc:  71.81;    3286 s elapsed
Epoch  2,  1201/ 1699; avg loss: 0.79; acc:  72.12;    3428 s elapsed
Epoch  2,  1251/ 1699; avg loss: 0.80; acc:  72.41;    3574 s elapsed
Epoch  2,  1301/ 1699; avg loss: 0.77; acc:  73.72;    3715 s elapsed
Epoch  2,  1351/ 1699; avg loss: 0.75; acc:  74.78;    3861 s elapsed
Epoch  2,  1401/ 1699; avg loss: 0.78; acc:  73.34;    4004 s elapsed
Epoch  2,  1451/ 1699; avg loss: 0.83; acc:  71.53;    4143 s elapsed
Epoch  2,  1501/ 1699; avg loss: 0.77; acc:  73.84;    4281 s elapsed
Epoch  2,  1551/ 1699; avg loss: 0.78; acc:  72.91;    4420 s elapsed
Epoch  2,  1601/ 1699; avg loss: 0.78; acc:  72.38;    4562 s elapsed
Epoch  2,  1651/ 1699; avg loss: 0.79; acc:  73.28;    4704 s elapsed
Epoch 2:	 average loss: 0.79	 train accuracy: 73.0866
====================
Evaluating on validation set:
Validation loss: 1.33
Validation accuracy: 64.15
====================

Epoch  3,     1/ 1699; avg loss: 0.67; acc:  75.00;    4854 s elapsed
Epoch  3,    51/ 1699; avg loss: 0.70; acc:  75.81;    4993 s elapsed
Epoch  3,   101/ 1699; avg loss: 0.69; acc:  75.78;    5136 s elapsed
Epoch  3,   151/ 1699; avg loss: 0.68; acc:  75.53;    5276 s elapsed
Epoch  3,   201/ 1699; avg loss: 0.68; acc:  75.34;    5420 s elapsed
Epoch  3,   251/ 1699; avg loss: 0.73; acc:  74.75;    5564 s elapsed
Epoch  3,   301/ 1699; avg loss: 0.72; acc:  75.72;    5706 s elapsed
Epoch  3,   351/ 1699; avg loss: 0.74; acc:  74.97;    5850 s elapsed
Epoch  3,   401/ 1699; avg loss: 0.70; acc:  76.78;    5992 s elapsed
Epoch  3,   451/ 1699; avg loss: 0.73; acc:  74.69;    6138 s elapsed
Epoch  3,   501/ 1699; avg loss: 0.70; acc:  75.56;    6282 s elapsed
Epoch  3,   551/ 1699; avg loss: 0.74; acc:  74.78;    6425 s elapsed
Epoch  3,   601/ 1699; avg loss: 0.75; acc:  74.31;    6573 s elapsed
Epoch  3,   651/ 1699; avg loss: 0.74; acc:  73.50;    6716 s elapsed
Epoch  3,   701/ 1699; avg loss: 0.74; acc:  74.19;    6853 s elapsed
Epoch  3,   751/ 1699; avg loss: 0.70; acc:  75.81;    6994 s elapsed
Epoch  3,   801/ 1699; avg loss: 0.72; acc:  74.91;    7138 s elapsed
Epoch  3,   851/ 1699; avg loss: 0.69; acc:  75.31;    7276 s elapsed
Epoch  3,   901/ 1699; avg loss: 0.73; acc:  73.97;    7422 s elapsed
Epoch  3,   951/ 1699; avg loss: 0.74; acc:  74.62;    7566 s elapsed
Epoch  3,  1001/ 1699; avg loss: 0.70; acc:  76.16;    7706 s elapsed
Epoch  3,  1051/ 1699; avg loss: 0.73; acc:  75.38;    7853 s elapsed
Epoch  3,  1101/ 1699; avg loss: 0.71; acc:  76.03;    7993 s elapsed
Epoch  3,  1151/ 1699; avg loss: 0.72; acc:  75.12;    8137 s elapsed
Epoch  3,  1201/ 1699; avg loss: 0.75; acc:  74.38;    8281 s elapsed
Epoch  3,  1251/ 1699; avg loss: 0.75; acc:  75.00;    8423 s elapsed
Epoch  3,  1301/ 1699; avg loss: 0.72; acc:  74.28;    8564 s elapsed
Epoch  3,  1351/ 1699; avg loss: 0.74; acc:  74.94;    8706 s elapsed
Epoch  3,  1401/ 1699; avg loss: 0.72; acc:  74.69;    8844 s elapsed
Epoch  3,  1451/ 1699; avg loss: 0.75; acc:  74.84;    8986 s elapsed
Epoch  3,  1501/ 1699; avg loss: 0.70; acc:  76.28;    9130 s elapsed
Epoch  3,  1551/ 1699; avg loss: 0.72; acc:  75.31;    9273 s elapsed
Epoch  3,  1601/ 1699; avg loss: 0.73; acc:  74.62;    9415 s elapsed
Epoch  3,  1651/ 1699; avg loss: 0.74; acc:  74.69;    9557 s elapsed
Epoch 3:	 average loss: 0.72	 train accuracy: 75.0872
====================
Evaluating on validation set:
Validation loss: 1.26
Validation accuracy: 66.15
====================

Epoch  4,     1/ 1699; avg loss: 0.69; acc:  68.75;    9708 s elapsed
Epoch  4,    51/ 1699; avg loss: 0.62; acc:  78.00;    9852 s elapsed
Epoch  4,   101/ 1699; avg loss: 0.64; acc:  77.53;    9995 s elapsed
Epoch  4,   151/ 1699; avg loss: 0.67; acc:  76.78;   10140 s elapsed
Epoch  4,   201/ 1699; avg loss: 0.63; acc:  78.16;   10284 s elapsed
Epoch  4,   251/ 1699; avg loss: 0.68; acc:  75.78;   10428 s elapsed
Epoch  4,   301/ 1699; avg loss: 0.66; acc:  77.16;   10571 s elapsed
Epoch  4,   351/ 1699; avg loss: 0.64; acc:  77.44;   10717 s elapsed
Epoch  4,   401/ 1699; avg loss: 0.66; acc:  76.03;   10862 s elapsed
Epoch  4,   451/ 1699; avg loss: 0.66; acc:  77.66;   11004 s elapsed
Epoch  4,   501/ 1699; avg loss: 0.65; acc:  78.28;   11141 s elapsed
Epoch  4,   551/ 1699; avg loss: 0.70; acc:  76.59;   11284 s elapsed
Epoch  4,   601/ 1699; avg loss: 0.66; acc:  77.38;   11425 s elapsed
Epoch  4,   651/ 1699; avg loss: 0.66; acc:  76.69;   11572 s elapsed
Epoch  4,   701/ 1699; avg loss: 0.68; acc:  76.34;   11712 s elapsed
Epoch  4,   751/ 1699; avg loss: 0.68; acc:  76.00;   11857 s elapsed
Epoch  4,   801/ 1699; avg loss: 0.68; acc:  76.34;   12001 s elapsed
Epoch  4,   851/ 1699; avg loss: 0.69; acc:  75.47;   12146 s elapsed
Epoch  4,   901/ 1699; avg loss: 0.69; acc:  76.09;   12284 s elapsed
Epoch  4,   951/ 1699; avg loss: 0.67; acc:  76.34;   12422 s elapsed
Epoch  4,  1001/ 1699; avg loss: 0.70; acc:  75.56;   12568 s elapsed
Epoch  4,  1051/ 1699; avg loss: 0.69; acc:  76.44;   12713 s elapsed
Epoch  4,  1101/ 1699; avg loss: 0.71; acc:  75.41;   12858 s elapsed
Epoch  4,  1151/ 1699; avg loss: 0.71; acc:  76.03;   12998 s elapsed
Epoch  4,  1201/ 1699; avg loss: 0.72; acc:  74.97;   13142 s elapsed
Epoch  4,  1251/ 1699; avg loss: 0.70; acc:  75.72;   13283 s elapsed
Epoch  4,  1301/ 1699; avg loss: 0.69; acc:  75.28;   13426 s elapsed
Epoch  4,  1351/ 1699; avg loss: 0.70; acc:  76.09;   13569 s elapsed
Epoch  4,  1401/ 1699; avg loss: 0.72; acc:  75.47;   13710 s elapsed
Epoch  4,  1451/ 1699; avg loss: 0.69; acc:  76.12;   13855 s elapsed
Epoch  4,  1501/ 1699; avg loss: 0.69; acc:  75.53;   14001 s elapsed
Epoch  4,  1551/ 1699; avg loss: 0.66; acc:  76.56;   14141 s elapsed
Epoch  4,  1601/ 1699; avg loss: 0.71; acc:  75.31;   14283 s elapsed
Epoch  4,  1651/ 1699; avg loss: 0.69; acc:  76.22;   14426 s elapsed
Epoch 4:	 average loss: 0.68	 train accuracy: 76.2958
====================
Evaluating on validation set:
Validation loss: 1.31
Validation accuracy: 65.1
====================

Epoch  5,     1/ 1699; avg loss: 0.62; acc:  82.81;   14575 s elapsed
Epoch  5,    51/ 1699; avg loss: 0.60; acc:  78.72;   14715 s elapsed
Epoch  5,   101/ 1699; avg loss: 0.57; acc:  79.34;   14854 s elapsed
Epoch  5,   151/ 1699; avg loss: 0.61; acc:  79.25;   14995 s elapsed
Epoch  5,   201/ 1699; avg loss: 0.62; acc:  78.75;   15141 s elapsed
Epoch  5,   251/ 1699; avg loss: 0.60; acc:  79.12;   15288 s elapsed
Epoch  5,   301/ 1699; avg loss: 0.63; acc:  77.94;   15429 s elapsed
Epoch  5,   351/ 1699; avg loss: 0.62; acc:  78.25;   15575 s elapsed
Epoch  5,   401/ 1699; avg loss: 0.63; acc:  77.19;   15716 s elapsed
Epoch  5,   451/ 1699; avg loss: 0.66; acc:  76.97;   15860 s elapsed
Epoch  5,   501/ 1699; avg loss: 0.62; acc:  78.12;   15999 s elapsed
Epoch  5,   551/ 1699; avg loss: 0.65; acc:  76.97;   16141 s elapsed
Epoch  5,   601/ 1699; avg loss: 0.64; acc:  77.59;   16282 s elapsed
Epoch  5,   651/ 1699; avg loss: 0.68; acc:  75.62;   16424 s elapsed
Epoch  5,   701/ 1699; avg loss: 0.63; acc:  78.75;   16571 s elapsed
Epoch  5,   751/ 1699; avg loss: 0.65; acc:  76.91;   16711 s elapsed
Epoch  5,   801/ 1699; avg loss: 0.65; acc:  77.19;   16853 s elapsed
Epoch  5,   851/ 1699; avg loss: 0.64; acc:  77.81;   16993 s elapsed
Epoch  5,   901/ 1699; avg loss: 0.66; acc:  76.66;   17135 s elapsed
Epoch  5,   951/ 1699; avg loss: 0.66; acc:  77.56;   17277 s elapsed
Epoch  5,  1001/ 1699; avg loss: 0.71; acc:  76.09;   17418 s elapsed
Epoch  5,  1051/ 1699; avg loss: 0.68; acc:  76.22;   17561 s elapsed
Epoch  5,  1101/ 1699; avg loss: 0.67; acc:  76.03;   17702 s elapsed
Epoch  5,  1151/ 1699; avg loss: 0.62; acc:  77.94;   17842 s elapsed
Epoch  5,  1201/ 1699; avg loss: 0.65; acc:  77.47;   17989 s elapsed
Epoch  5,  1251/ 1699; avg loss: 0.68; acc:  77.25;   18132 s elapsed
Epoch  5,  1301/ 1699; avg loss: 0.66; acc:  77.00;   18273 s elapsed
Epoch  5,  1351/ 1699; avg loss: 0.68; acc:  76.44;   18419 s elapsed
Epoch  5,  1401/ 1699; avg loss: 0.68; acc:  76.50;   18560 s elapsed
Epoch  5,  1451/ 1699; avg loss: 0.68; acc:  76.81;   18700 s elapsed
Epoch  5,  1501/ 1699; avg loss: 0.64; acc:  77.56;   18843 s elapsed
Epoch  5,  1551/ 1699; avg loss: 0.68; acc:  76.41;   18989 s elapsed
Epoch  5,  1601/ 1699; avg loss: 0.62; acc:  77.38;   19131 s elapsed
Epoch  5,  1651/ 1699; avg loss: 0.69; acc:  76.38;   19276 s elapsed
Epoch 5:	 average loss: 0.65	 train accuracy: 77.3305
====================
Evaluating on validation set:
Validation loss: 1.26
Validation accuracy: 66.25
====================

Epoch  6,     1/ 1699; avg loss: 0.72; acc:  70.31;   19431 s elapsed
Epoch  6,    51/ 1699; avg loss: 0.56; acc:  79.66;   19577 s elapsed
Epoch  6,   101/ 1699; avg loss: 0.59; acc:  79.56;   19717 s elapsed
Epoch  6,   151/ 1699; avg loss: 0.55; acc:  80.22;   19854 s elapsed
Epoch  6,   201/ 1699; avg loss: 0.56; acc:  79.34;   19992 s elapsed
Epoch  6,   251/ 1699; avg loss: 0.58; acc:  79.34;   20131 s elapsed
Epoch  6,   301/ 1699; avg loss: 0.57; acc:  80.28;   20276 s elapsed
Epoch  6,   351/ 1699; avg loss: 0.62; acc:  78.66;   20419 s elapsed
Epoch  6,   401/ 1699; avg loss: 0.62; acc:  78.53;   20560 s elapsed
Epoch  6,   451/ 1699; avg loss: 0.61; acc:  78.22;   20704 s elapsed
Epoch  6,   501/ 1699; avg loss: 0.62; acc:  77.56;   20845 s elapsed
Epoch  6,   551/ 1699; avg loss: 0.63; acc:  77.50;   20991 s elapsed
Epoch  6,   601/ 1699; avg loss: 0.62; acc:  78.03;   21132 s elapsed
Epoch  6,   651/ 1699; avg loss: 0.64; acc:  77.62;   21278 s elapsed
Epoch  6,   701/ 1699; avg loss: 0.63; acc:  77.59;   21421 s elapsed
Epoch  6,   751/ 1699; avg loss: 0.63; acc:  78.44;   21561 s elapsed
Epoch  6,   801/ 1699; avg loss: 0.61; acc:  78.59;   21704 s elapsed
Epoch  6,   851/ 1699; avg loss: 0.60; acc:  78.06;   21843 s elapsed
Epoch  6,   901/ 1699; avg loss: 0.64; acc:  78.06;   21985 s elapsed
Epoch  6,   951/ 1699; avg loss: 0.65; acc:  77.00;   22125 s elapsed
Epoch  6,  1001/ 1699; avg loss: 0.66; acc:  76.81;   22268 s elapsed
Epoch  6,  1051/ 1699; avg loss: 0.62; acc:  78.41;   22409 s elapsed
Epoch  6,  1101/ 1699; avg loss: 0.63; acc:  77.91;   22551 s elapsed
Epoch  6,  1151/ 1699; avg loss: 0.64; acc:  78.22;   22694 s elapsed
Epoch  6,  1201/ 1699; avg loss: 0.61; acc:  78.50;   22840 s elapsed
Epoch  6,  1251/ 1699; avg loss: 0.64; acc:  77.03;   22985 s elapsed
Epoch  6,  1301/ 1699; avg loss: 0.65; acc:  77.28;   23131 s elapsed
Epoch  6,  1351/ 1699; avg loss: 0.64; acc:  78.38;   23278 s elapsed
Epoch  6,  1401/ 1699; avg loss: 0.63; acc:  76.94;   23421 s elapsed
Epoch  6,  1451/ 1699; avg loss: 0.63; acc:  78.59;   23564 s elapsed
Epoch  6,  1501/ 1699; avg loss: 0.66; acc:  77.81;   23707 s elapsed
Epoch  6,  1551/ 1699; avg loss: 0.66; acc:  77.81;   23850 s elapsed
Epoch  6,  1601/ 1699; avg loss: 0.66; acc:  77.09;   23990 s elapsed
Epoch  6,  1651/ 1699; avg loss: 0.63; acc:  77.91;   24133 s elapsed
Epoch 6:	 average loss: 0.62	 train accuracy: 78.1924
====================
Evaluating on validation set:
Validation loss: 1.26
Validation accuracy: 65.7
====================

Epoch  7,     1/ 1699; avg loss: 0.58; acc:  78.12;   24282 s elapsed
Epoch  7,    51/ 1699; avg loss: 0.52; acc:  81.12;   24423 s elapsed
Epoch  7,   101/ 1699; avg loss: 0.54; acc:  81.38;   24565 s elapsed
Epoch  7,   151/ 1699; avg loss: 0.54; acc:  80.59;   24708 s elapsed
Epoch  7,   201/ 1699; avg loss: 0.54; acc:  80.81;   24849 s elapsed
Epoch  7,   251/ 1699; avg loss: 0.55; acc:  80.69;   24990 s elapsed
Epoch  7,   301/ 1699; avg loss: 0.57; acc:  79.38;   25128 s elapsed
Epoch  7,   351/ 1699; avg loss: 0.54; acc:  80.91;   25271 s elapsed
Epoch  7,   401/ 1699; avg loss: 0.55; acc:  80.94;   25411 s elapsed
Epoch  7,   451/ 1699; avg loss: 0.58; acc:  79.03;   25555 s elapsed
Epoch  7,   501/ 1699; avg loss: 0.56; acc:  80.38;   25698 s elapsed
Epoch  7,   551/ 1699; avg loss: 0.59; acc:  78.97;   25841 s elapsed
Epoch  7,   601/ 1699; avg loss: 0.58; acc:  79.66;   25986 s elapsed
Epoch  7,   651/ 1699; avg loss: 0.59; acc:  78.56;   26130 s elapsed
Epoch  7,   701/ 1699; avg loss: 0.56; acc:  80.19;   26272 s elapsed
Epoch  7,   751/ 1699; avg loss: 0.60; acc:  78.97;   26419 s elapsed
Epoch  7,   801/ 1699; avg loss: 0.64; acc:  78.03;   26563 s elapsed
Epoch  7,   851/ 1699; avg loss: 0.59; acc:  78.75;   26702 s elapsed
Epoch  7,   901/ 1699; avg loss: 0.63; acc:  77.66;   26844 s elapsed
Epoch  7,   951/ 1699; avg loss: 0.59; acc:  79.84;   26991 s elapsed
Epoch  7,  1001/ 1699; avg loss: 0.64; acc:  77.91;   27133 s elapsed
Epoch  7,  1051/ 1699; avg loss: 0.65; acc:  77.69;   27279 s elapsed
Epoch  7,  1101/ 1699; avg loss: 0.60; acc:  80.03;   27422 s elapsed
Epoch  7,  1151/ 1699; avg loss: 0.59; acc:  79.00;   27562 s elapsed
Epoch  7,  1201/ 1699; avg loss: 0.62; acc:  78.91;   27702 s elapsed
Epoch  7,  1251/ 1699; avg loss: 0.65; acc:  78.06;   27844 s elapsed
Epoch  7,  1301/ 1699; avg loss: 0.62; acc:  77.78;   27983 s elapsed
Epoch  7,  1351/ 1699; avg loss: 0.62; acc:  78.88;   28125 s elapsed
Epoch  7,  1401/ 1699; avg loss: 0.65; acc:  77.47;   28267 s elapsed
Epoch  7,  1451/ 1699; avg loss: 0.61; acc:  79.09;   28407 s elapsed
Epoch  7,  1501/ 1699; avg loss: 0.60; acc:  79.06;   28553 s elapsed
Epoch  7,  1551/ 1699; avg loss: 0.63; acc:  78.69;   28695 s elapsed
Epoch  7,  1601/ 1699; avg loss: 0.64; acc:  78.09;   28839 s elapsed
Epoch  7,  1651/ 1699; avg loss: 0.62; acc:  78.44;   28984 s elapsed
Epoch 7:	 average loss: 0.59	 train accuracy: 79.2097
====================
Evaluating on validation set:
Validation loss: 1.28
Validation accuracy: 66.3
====================

Epoch  8,     1/ 1699; avg loss: 0.40; acc:  84.38;   29133 s elapsed
Epoch  8,    51/ 1699; avg loss: 0.51; acc:  81.56;   29276 s elapsed
Epoch  8,   101/ 1699; avg loss: 0.50; acc:  82.22;   29417 s elapsed
Epoch  8,   151/ 1699; avg loss: 0.53; acc:  81.34;   29562 s elapsed
Epoch  8,   201/ 1699; avg loss: 0.51; acc:  82.47;   29705 s elapsed
Epoch  8,   251/ 1699; avg loss: 0.49; acc:  83.19;   29845 s elapsed
Epoch  8,   301/ 1699; avg loss: 0.53; acc:  81.25;   29984 s elapsed
Epoch  8,   351/ 1699; avg loss: 0.56; acc:  80.16;   30120 s elapsed
Epoch  8,   401/ 1699; avg loss: 0.54; acc:  81.41;   30266 s elapsed
Epoch  8,   451/ 1699; avg loss: 0.55; acc:  81.66;   30409 s elapsed
Epoch  8,   501/ 1699; avg loss: 0.58; acc:  80.06;   30551 s elapsed
Epoch  8,   551/ 1699; avg loss: 0.55; acc:  81.31;   30698 s elapsed
Epoch  8,   601/ 1699; avg loss: 0.53; acc:  81.25;   30846 s elapsed
Epoch  8,   651/ 1699; avg loss: 0.57; acc:  79.59;   30992 s elapsed
Epoch  8,   701/ 1699; avg loss: 0.59; acc:  79.88;   31133 s elapsed
Epoch  8,   751/ 1699; avg loss: 0.58; acc:  79.47;   31278 s elapsed
Epoch  8,   801/ 1699; avg loss: 0.56; acc:  80.75;   31422 s elapsed
Epoch  8,   851/ 1699; avg loss: 0.58; acc:  80.34;   31568 s elapsed
Epoch  8,   901/ 1699; avg loss: 0.59; acc:  79.44;   31711 s elapsed
Epoch  8,   951/ 1699; avg loss: 0.57; acc:  79.66;   31851 s elapsed
Epoch  8,  1001/ 1699; avg loss: 0.59; acc:  78.75;   31995 s elapsed
Epoch  8,  1051/ 1699; avg loss: 0.62; acc:  78.78;   32134 s elapsed
Epoch  8,  1101/ 1699; avg loss: 0.63; acc:  77.69;   32273 s elapsed
Epoch  8,  1151/ 1699; avg loss: 0.59; acc:  78.97;   32414 s elapsed
Epoch  8,  1201/ 1699; avg loss: 0.60; acc:  79.31;   32557 s elapsed
Epoch  8,  1251/ 1699; avg loss: 0.61; acc:  78.41;   32698 s elapsed
Epoch  8,  1301/ 1699; avg loss: 0.57; acc:  79.94;   32840 s elapsed
Epoch  8,  1351/ 1699; avg loss: 0.62; acc:  78.12;   32980 s elapsed
Epoch  8,  1401/ 1699; avg loss: 0.59; acc:  79.53;   33123 s elapsed
Epoch  8,  1451/ 1699; avg loss: 0.62; acc:  78.56;   33265 s elapsed
Epoch  8,  1501/ 1699; avg loss: 0.62; acc:  78.25;   33405 s elapsed
Epoch  8,  1551/ 1699; avg loss: 0.61; acc:  79.06;   33546 s elapsed
Epoch  8,  1601/ 1699; avg loss: 0.58; acc:  79.91;   33689 s elapsed
Epoch  8,  1651/ 1699; avg loss: 0.60; acc:  78.53;   33827 s elapsed
Epoch 8:	 average loss: 0.57	 train accuracy: 79.9777
====================
Evaluating on validation set:
Validation loss: 1.29
Validation accuracy: 66.05
====================

Epoch  9,     1/ 1699; avg loss: 0.39; acc:  85.94;   33986 s elapsed
Epoch  9,    51/ 1699; avg loss: 0.48; acc:  83.31;   34129 s elapsed
Epoch  9,   101/ 1699; avg loss: 0.48; acc:  83.12;   34268 s elapsed
Epoch  9,   151/ 1699; avg loss: 0.51; acc:  82.62;   34412 s elapsed
Epoch  9,   201/ 1699; avg loss: 0.46; acc:  83.88;   34551 s elapsed
Epoch  9,   251/ 1699; avg loss: 0.49; acc:  82.53;   34691 s elapsed
Epoch  9,   301/ 1699; avg loss: 0.50; acc:  83.09;   34832 s elapsed
Epoch  9,   351/ 1699; avg loss: 0.54; acc:  81.31;   34970 s elapsed
Epoch  9,   401/ 1699; avg loss: 0.52; acc:  81.03;   35113 s elapsed
Epoch  9,   451/ 1699; avg loss: 0.51; acc:  81.88;   35256 s elapsed
Epoch  9,   501/ 1699; avg loss: 0.53; acc:  81.28;   35396 s elapsed
Epoch  9,   551/ 1699; avg loss: 0.58; acc:  79.41;   35540 s elapsed
Epoch  9,   601/ 1699; avg loss: 0.55; acc:  80.75;   35681 s elapsed
Epoch  9,   651/ 1699; avg loss: 0.57; acc:  80.03;   35824 s elapsed
Epoch  9,   701/ 1699; avg loss: 0.54; acc:  80.75;   35964 s elapsed
Epoch  9,   751/ 1699; avg loss: 0.51; acc:  82.09;   36108 s elapsed
Epoch  9,   801/ 1699; avg loss: 0.55; acc:  81.25;   36250 s elapsed
Epoch  9,   851/ 1699; avg loss: 0.57; acc:  80.69;   36395 s elapsed
Epoch  9,   901/ 1699; avg loss: 0.58; acc:  80.31;   36539 s elapsed
Epoch  9,   951/ 1699; avg loss: 0.58; acc:  79.91;   36679 s elapsed
Epoch  9,  1001/ 1699; avg loss: 0.62; acc:  78.22;   36821 s elapsed
Epoch  9,  1051/ 1699; avg loss: 0.54; acc:  81.66;   36964 s elapsed
Epoch  9,  1101/ 1699; avg loss: 0.58; acc:  79.75;   37111 s elapsed
Epoch  9,  1151/ 1699; avg loss: 0.57; acc:  80.16;   37254 s elapsed
Epoch  9,  1201/ 1699; avg loss: 0.57; acc:  80.25;   37397 s elapsed
Epoch  9,  1251/ 1699; avg loss: 0.57; acc:  80.12;   37541 s elapsed
Epoch  9,  1301/ 1699; avg loss: 0.57; acc:  79.53;   37681 s elapsed
Epoch  9,  1351/ 1699; avg loss: 0.56; acc:  80.62;   37822 s elapsed
Epoch  9,  1401/ 1699; avg loss: 0.57; acc:  79.09;   37969 s elapsed
Epoch  9,  1451/ 1699; avg loss: 0.63; acc:  77.84;   38110 s elapsed
Epoch  9,  1501/ 1699; avg loss: 0.57; acc:  80.38;   38256 s elapsed
Epoch  9,  1551/ 1699; avg loss: 0.57; acc:  80.41;   38402 s elapsed
Epoch  9,  1601/ 1699; avg loss: 0.61; acc:  78.44;   38546 s elapsed
Epoch  9,  1651/ 1699; avg loss: 0.59; acc:  79.25;   38683 s elapsed
Epoch 9:	 average loss: 0.55	 train accuracy: 80.7366
====================
Evaluating on validation set:
Validation loss: 1.27
Validation accuracy: 67.25
====================

Epoch 10,     1/ 1699; avg loss: 0.36; acc:  85.94;   38833 s elapsed
Epoch 10,    51/ 1699; avg loss: 0.44; acc:  84.28;   38974 s elapsed
Epoch 10,   101/ 1699; avg loss: 0.44; acc:  85.25;   39114 s elapsed
Epoch 10,   151/ 1699; avg loss: 0.46; acc:  83.59;   39257 s elapsed
Epoch 10,   201/ 1699; avg loss: 0.47; acc:  84.06;   39403 s elapsed
Epoch 10,   251/ 1699; avg loss: 0.46; acc:  83.47;   39547 s elapsed
Epoch 10,   301/ 1699; avg loss: 0.48; acc:  82.78;   39693 s elapsed
Epoch 10,   351/ 1699; avg loss: 0.48; acc:  82.56;   39835 s elapsed
Epoch 10,   401/ 1699; avg loss: 0.51; acc:  82.03;   39981 s elapsed
Epoch 10,   451/ 1699; avg loss: 0.50; acc:  82.19;   40128 s elapsed
Epoch 10,   501/ 1699; avg loss: 0.51; acc:  81.50;   40272 s elapsed
Epoch 10,   551/ 1699; avg loss: 0.53; acc:  81.00;   40417 s elapsed
Epoch 10,   601/ 1699; avg loss: 0.51; acc:  81.41;   40558 s elapsed
Epoch 10,   651/ 1699; avg loss: 0.54; acc:  80.78;   40701 s elapsed
Epoch 10,   701/ 1699; avg loss: 0.53; acc:  81.84;   40842 s elapsed
Epoch 10,   751/ 1699; avg loss: 0.53; acc:  81.94;   40983 s elapsed
Epoch 10,   801/ 1699; avg loss: 0.54; acc:  80.50;   41125 s elapsed
Epoch 10,   851/ 1699; avg loss: 0.54; acc:  81.53;   41263 s elapsed
Epoch 10,   901/ 1699; avg loss: 0.55; acc:  80.56;   41404 s elapsed
Epoch 10,   951/ 1699; avg loss: 0.55; acc:  80.78;   41550 s elapsed
Epoch 10,  1001/ 1699; avg loss: 0.54; acc:  80.44;   41691 s elapsed
Epoch 10,  1051/ 1699; avg loss: 0.57; acc:  80.16;   41832 s elapsed
Epoch 10,  1101/ 1699; avg loss: 0.54; acc:  80.91;   41976 s elapsed
Epoch 10,  1151/ 1699; avg loss: 0.55; acc:  80.31;   42120 s elapsed
Epoch 10,  1201/ 1699; avg loss: 0.56; acc:  80.62;   42264 s elapsed
Epoch 10,  1251/ 1699; avg loss: 0.55; acc:  81.03;   42409 s elapsed
Epoch 10,  1301/ 1699; avg loss: 0.56; acc:  79.91;   42548 s elapsed
Epoch 10,  1351/ 1699; avg loss: 0.56; acc:  80.00;   42692 s elapsed
Epoch 10,  1401/ 1699; avg loss: 0.59; acc:  79.66;   42838 s elapsed
Epoch 10,  1451/ 1699; avg loss: 0.58; acc:  80.25;   42977 s elapsed
Epoch 10,  1501/ 1699; avg loss: 0.55; acc:  80.97;   43119 s elapsed
Epoch 10,  1551/ 1699; avg loss: 0.57; acc:  80.31;   43256 s elapsed
Epoch 10,  1601/ 1699; avg loss: 0.57; acc:  80.03;   43396 s elapsed
Epoch 10,  1651/ 1699; avg loss: 0.55; acc:  79.97;   43534 s elapsed
Epoch 10:	 average loss: 0.53	 train accuracy: 81.3712
====================
Evaluating on validation set:
Validation loss: 1.21
Validation accuracy: 67.95
====================
Namespace(batch_size=64, dict='data/CBTest/data/cbtest_NE_train.txtdict.pt', dropout=0.1, embed_size=384, epochs=50, gpu=0, gru_size=384, learning_rate=0.001, log_interval=50, save_model='model_simplegru', start_epoch=1, train_from='models/model_simplegru_epoch10_acc_67.95.pt', traindata='data/CBTest/data/cbtest_NE_train.txt.pt', validdata='data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt', weight_decay=0.0001)
('Loading dictrionary from ', 'data/CBTest/data/cbtest_NE_train.txtdict.pt')
('Loading train data from ', 'data/CBTest/data/cbtest_NE_train.txt.pt')
('Loading valid data from ', 'data/CBTest/data/cbtest_NE_valid_2000ex.txt.pt')
 * vocabulary size = 15683
 * number of training samples. 108719
 * maximum batch size. 64
Building model...
Loading model from checkpoint at 
* number of parameters: 7796352
AoAReader(
  (embedding): Embedding(15683, 384, padding_idx=0)
  (gru): SimpleGRU(384, 384, batch_first=True, dropout=0.1, bidirectional=True)
)

Epoch 11,     1/ 1699; avg loss: 0.39; acc:  85.94;       3 s elapsed
Epoch 11,    51/ 1699; avg loss: 0.42; acc:  86.19;     152 s elapsed
Epoch 11,   101/ 1699; avg loss: 0.42; acc:  84.97;     292 s elapsed
Epoch 11,   151/ 1699; avg loss: 0.44; acc:  84.69;     436 s elapsed
Epoch 11,   201/ 1699; avg loss: 0.45; acc:  83.81;     580 s elapsed
Epoch 11,   251/ 1699; avg loss: 0.46; acc:  84.12;     722 s elapsed
Epoch 11,   301/ 1699; avg loss: 0.44; acc:  84.38;     865 s elapsed
Epoch 11,   351/ 1699; avg loss: 0.47; acc:  84.72;    1007 s elapsed
Epoch 11,   401/ 1699; avg loss: 0.50; acc:  82.88;    1150 s elapsed
Epoch 11,   451/ 1699; avg loss: 0.48; acc:  82.50;    1296 s elapsed
Epoch 11,   501/ 1699; avg loss: 0.49; acc:  82.19;    1433 s elapsed
Epoch 11,   551/ 1699; avg loss: 0.48; acc:  84.06;    1578 s elapsed
Epoch 11,   601/ 1699; avg loss: 0.50; acc:  83.06;    1720 s elapsed
Epoch 11,   651/ 1699; avg loss: 0.50; acc:  82.75;    1865 s elapsed
Epoch 11,   701/ 1699; avg loss: 0.48; acc:  82.53;    2005 s elapsed
Epoch 11,   751/ 1699; avg loss: 0.50; acc:  81.97;    2148 s elapsed
Epoch 11,   801/ 1699; avg loss: 0.50; acc:  83.34;    2288 s elapsed
Epoch 11,   851/ 1699; avg loss: 0.52; acc:  82.47;    2428 s elapsed
Epoch 11,   901/ 1699; avg loss: 0.54; acc:  82.31;    2566 s elapsed
Epoch 11,   951/ 1699; avg loss: 0.49; acc:  82.94;    2705 s elapsed
Epoch 11,  1001/ 1699; avg loss: 0.52; acc:  81.72;    2848 s elapsed
Epoch 11,  1051/ 1699; avg loss: 0.53; acc:  81.38;    2990 s elapsed
Epoch 11,  1101/ 1699; avg loss: 0.51; acc:  81.78;    3130 s elapsed
Epoch 11,  1151/ 1699; avg loss: 0.55; acc:  80.59;    3273 s elapsed
Epoch 11,  1201/ 1699; avg loss: 0.58; acc:  79.56;    3416 s elapsed
Epoch 11,  1251/ 1699; avg loss: 0.54; acc:  81.06;    3558 s elapsed
Epoch 11,  1301/ 1699; avg loss: 0.55; acc:  81.28;    3700 s elapsed
Epoch 11,  1351/ 1699; avg loss: 0.56; acc:  80.06;    3845 s elapsed
Epoch 11,  1401/ 1699; avg loss: 0.51; acc:  82.31;    3987 s elapsed
Epoch 11,  1451/ 1699; avg loss: 0.57; acc:  80.78;    4130 s elapsed
Epoch 11,  1501/ 1699; avg loss: 0.56; acc:  80.12;    4275 s elapsed
Epoch 11,  1551/ 1699; avg loss: 0.55; acc:  81.41;    4416 s elapsed
Epoch 11,  1601/ 1699; avg loss: 0.54; acc:  81.22;    4559 s elapsed
Epoch 11,  1651/ 1699; avg loss: 0.57; acc:  80.53;    4698 s elapsed
Epoch 11:	 average loss: 0.51	 train accuracy: 82.3747
====================
Evaluating on validation set:
Validation loss: 1.33
Validation accuracy: 67.3
====================

Epoch 12,     1/ 1699; avg loss: 0.41; acc:  89.06;    4849 s elapsed
Epoch 12,    51/ 1699; avg loss: 0.41; acc:  85.66;    4993 s elapsed
Epoch 12,   101/ 1699; avg loss: 0.41; acc:  85.69;    5131 s elapsed
Epoch 12,   151/ 1699; avg loss: 0.42; acc:  85.12;    5271 s elapsed
Epoch 12,   201/ 1699; avg loss: 0.44; acc:  84.78;    5411 s elapsed
Epoch 12,   251/ 1699; avg loss: 0.44; acc:  84.41;    5555 s elapsed
Epoch 12,   301/ 1699; avg loss: 0.43; acc:  85.59;    5697 s elapsed
Epoch 12,   351/ 1699; avg loss: 0.44; acc:  84.62;    5838 s elapsed
Epoch 12,   401/ 1699; avg loss: 0.46; acc:  83.59;    5981 s elapsed
Epoch 12,   451/ 1699; avg loss: 0.46; acc:  83.31;    6127 s elapsed
Epoch 12,   501/ 1699; avg loss: 0.46; acc:  83.66;    6269 s elapsed
Epoch 12,   551/ 1699; avg loss: 0.49; acc:  82.00;    6408 s elapsed
Epoch 12,   601/ 1699; avg loss: 0.48; acc:  82.66;    6548 s elapsed
Epoch 12,   651/ 1699; avg loss: 0.47; acc:  83.22;    6694 s elapsed
Epoch 12,   701/ 1699; avg loss: 0.50; acc:  82.75;    6834 s elapsed
Epoch 12,   751/ 1699; avg loss: 0.49; acc:  82.88;    6976 s elapsed
Epoch 12,   801/ 1699; avg loss: 0.50; acc:  82.12;    7117 s elapsed
Epoch 12,   851/ 1699; avg loss: 0.49; acc:  82.41;    7253 s elapsed
Epoch 12,   901/ 1699; avg loss: 0.47; acc:  83.75;    7396 s elapsed
Epoch 12,   951/ 1699; avg loss: 0.51; acc:  82.03;    7539 s elapsed
Epoch 12,  1001/ 1699; avg loss: 0.51; acc:  82.47;    7684 s elapsed
Epoch 12,  1051/ 1699; avg loss: 0.49; acc:  83.00;    7831 s elapsed
Epoch 12,  1101/ 1699; avg loss: 0.54; acc:  81.34;    7970 s elapsed
Epoch 12,  1151/ 1699; avg loss: 0.52; acc:  81.78;    8113 s elapsed
Epoch 12,  1201/ 1699; avg loss: 0.55; acc:  81.28;    8258 s elapsed
Epoch 12,  1251/ 1699; avg loss: 0.52; acc:  81.41;    8402 s elapsed
Epoch 12,  1301/ 1699; avg loss: 0.53; acc:  81.72;    8543 s elapsed
Epoch 12,  1351/ 1699; avg loss: 0.52; acc:  81.28;    8684 s elapsed
Epoch 12,  1401/ 1699; avg loss: 0.50; acc:  81.19;    8829 s elapsed
Epoch 12,  1451/ 1699; avg loss: 0.52; acc:  81.84;    8972 s elapsed
Epoch 12,  1501/ 1699; avg loss: 0.51; acc:  82.31;    9118 s elapsed
Epoch 12,  1551/ 1699; avg loss: 0.51; acc:  81.62;    9259 s elapsed
Epoch 12,  1601/ 1699; avg loss: 0.52; acc:  81.59;    9403 s elapsed
Epoch 12,  1651/ 1699; avg loss: 0.52; acc:  81.59;    9546 s elapsed
Epoch 12:	 average loss: 0.49	 train accuracy: 82.8383
====================
Evaluating on validation set:
Validation loss: 1.30
Validation accuracy: 66.6
====================

Epoch 13,     1/ 1699; avg loss: 0.27; acc:  87.50;    9696 s elapsed
Epoch 13,    51/ 1699; avg loss: 0.39; acc:  87.66;    9840 s elapsed
Epoch 13,   101/ 1699; avg loss: 0.40; acc:  86.19;    9985 s elapsed
Epoch 13,   151/ 1699; avg loss: 0.40; acc:  86.47;   10132 s elapsed
Epoch 13,   201/ 1699; avg loss: 0.38; acc:  86.50;   10274 s elapsed
Epoch 13,   251/ 1699; avg loss: 0.42; acc:  86.06;   10417 s elapsed
Epoch 13,   301/ 1699; avg loss: 0.40; acc:  86.09;   10556 s elapsed
Epoch 13,   351/ 1699; avg loss: 0.42; acc:  85.41;   10698 s elapsed
Epoch 13,   401/ 1699; avg loss: 0.42; acc:  84.69;   10837 s elapsed
Epoch 13,   451/ 1699; avg loss: 0.45; acc:  84.25;   10981 s elapsed
Epoch 13,   501/ 1699; avg loss: 0.45; acc:  83.41;   11125 s elapsed
Epoch 13,   551/ 1699; avg loss: 0.47; acc:  83.59;   11268 s elapsed
Epoch 13,   601/ 1699; avg loss: 0.44; acc:  84.94;   11411 s elapsed
Epoch 13,   651/ 1699; avg loss: 0.46; acc:  84.28;   11552 s elapsed
Epoch 13,   701/ 1699; avg loss: 0.44; acc:  84.44;   11691 s elapsed
Epoch 13,   751/ 1699; avg loss: 0.46; acc:  84.16;   11832 s elapsed
Epoch 13,   801/ 1699; avg loss: 0.50; acc:  83.59;   11978 s elapsed
Epoch 13,   851/ 1699; avg loss: 0.49; acc:  83.84;   12121 s elapsed
Epoch 13,   901/ 1699; avg loss: 0.47; acc:  84.00;   12261 s elapsed
Epoch 13,   951/ 1699; avg loss: 0.49; acc:  82.69;   12403 s elapsed
Epoch 13,  1001/ 1699; avg loss: 0.49; acc:  83.06;   12543 s elapsed
Epoch 13,  1051/ 1699; avg loss: 0.50; acc:  82.53;   12684 s elapsed
Epoch 13,  1101/ 1699; avg loss: 0.49; acc:  82.75;   12824 s elapsed
Epoch 13,  1151/ 1699; avg loss: 0.51; acc:  82.59;   12966 s elapsed
Epoch 13,  1201/ 1699; avg loss: 0.49; acc:  83.53;   13113 s elapsed
Epoch 13,  1251/ 1699; avg loss: 0.52; acc:  81.62;   13250 s elapsed
Epoch 13,  1301/ 1699; avg loss: 0.50; acc:  83.00;   13391 s elapsed
Epoch 13,  1351/ 1699; avg loss: 0.50; acc:  82.81;   13534 s elapsed
Epoch 13,  1401/ 1699; avg loss: 0.50; acc:  81.97;   13674 s elapsed
Epoch 13,  1451/ 1699; avg loss: 0.53; acc:  82.19;   13817 s elapsed
Epoch 13,  1501/ 1699; avg loss: 0.52; acc:  81.91;   13964 s elapsed
Epoch 13,  1551/ 1699; avg loss: 0.54; acc:  80.97;   14113 s elapsed
Epoch 13,  1601/ 1699; avg loss: 0.52; acc:  81.44;   14251 s elapsed
Epoch 13,  1651/ 1699; avg loss: 0.51; acc:  82.06;   14394 s elapsed
Epoch 13:	 average loss: 0.47	 train accuracy: 83.7232
====================
Evaluating on validation set:
Validation loss: 1.30
Validation accuracy: 67.2
====================

Epoch 14,     1/ 1699; avg loss: 0.33; acc:  85.94;   14541 s elapsed
Epoch 14,    51/ 1699; avg loss: 0.35; acc:  87.97;   14681 s elapsed
Epoch 14,   101/ 1699; avg loss: 0.36; acc:  87.41;   14822 s elapsed
Epoch 14,   151/ 1699; avg loss: 0.39; acc:  88.25;   14966 s elapsed
Epoch 14,   201/ 1699; avg loss: 0.36; acc:  87.56;   15107 s elapsed
Epoch 14,   251/ 1699; avg loss: 0.39; acc:  86.75;   15249 s elapsed
Epoch 14,   301/ 1699; avg loss: 0.42; acc:  85.28;   15396 s elapsed
Epoch 14,   351/ 1699; avg loss: 0.42; acc:  85.69;   15536 s elapsed
Epoch 14,   401/ 1699; avg loss: 0.41; acc:  86.22;   15678 s elapsed
Epoch 14,   451/ 1699; avg loss: 0.41; acc:  86.28;   15818 s elapsed
Epoch 14,   501/ 1699; avg loss: 0.44; acc:  84.38;   15959 s elapsed
Epoch 14,   551/ 1699; avg loss: 0.43; acc:  85.88;   16103 s elapsed
Epoch 14,   601/ 1699; avg loss: 0.45; acc:  84.62;   16246 s elapsed
Epoch 14,   651/ 1699; avg loss: 0.44; acc:  84.59;   16388 s elapsed
Epoch 14,   701/ 1699; avg loss: 0.44; acc:  84.41;   16526 s elapsed
Epoch 14,   751/ 1699; avg loss: 0.44; acc:  83.53;   16668 s elapsed
Epoch 14,   801/ 1699; avg loss: 0.45; acc:  84.50;   16807 s elapsed
Epoch 14,   851/ 1699; avg loss: 0.44; acc:  84.31;   16953 s elapsed
Epoch 14,   901/ 1699; avg loss: 0.45; acc:  83.47;   17094 s elapsed
Epoch 14,   951/ 1699; avg loss: 0.45; acc:  83.34;   17236 s elapsed
Epoch 14,  1001/ 1699; avg loss: 0.49; acc:  83.25;   17379 s elapsed
Epoch 14,  1051/ 1699; avg loss: 0.47; acc:  83.78;   17525 s elapsed
Epoch 14,  1101/ 1699; avg loss: 0.49; acc:  83.06;   17665 s elapsed
Epoch 14,  1151/ 1699; avg loss: 0.47; acc:  82.84;   17804 s elapsed
Epoch 14,  1201/ 1699; avg loss: 0.50; acc:  82.72;   17945 s elapsed
Epoch 14,  1251/ 1699; avg loss: 0.48; acc:  84.00;   18090 s elapsed
Epoch 14,  1301/ 1699; avg loss: 0.49; acc:  82.53;   18232 s elapsed
Epoch 14,  1351/ 1699; avg loss: 0.48; acc:  83.62;   18377 s elapsed
Epoch 14,  1401/ 1699; avg loss: 0.48; acc:  83.56;   18520 s elapsed
Epoch 14,  1451/ 1699; avg loss: 0.51; acc:  81.62;   18661 s elapsed
Epoch 14,  1501/ 1699; avg loss: 0.50; acc:  82.75;   18803 s elapsed
Epoch 14,  1551/ 1699; avg loss: 0.51; acc:  82.56;   18943 s elapsed
Epoch 14,  1601/ 1699; avg loss: 0.49; acc:  82.78;   19090 s elapsed
Epoch 14,  1651/ 1699; avg loss: 0.50; acc:  83.00;   19235 s elapsed
Epoch 14:	 average loss: 0.45	 train accuracy: 84.3799
====================
Evaluating on validation set:
Validation loss: 1.32
Validation accuracy: 67.05
====================

Epoch 15,     1/ 1699; avg loss: 0.25; acc:  92.19;   19393 s elapsed
Epoch 15,    51/ 1699; avg loss: 0.36; acc:  87.50;   19531 s elapsed
Epoch 15,   101/ 1699; avg loss: 0.35; acc:  88.81;   19675 s elapsed
Epoch 15,   151/ 1699; avg loss: 0.34; acc:  89.25;   19814 s elapsed
Epoch 15,   201/ 1699; avg loss: 0.34; acc:  88.53;   19960 s elapsed
Epoch 15,   251/ 1699; avg loss: 0.37; acc:  87.91;   20100 s elapsed
Epoch 15,   301/ 1699; avg loss: 0.35; acc:  87.69;   20244 s elapsed
Epoch 15,   351/ 1699; avg loss: 0.40; acc:  86.06;   20385 s elapsed
Epoch 15,   401/ 1699; avg loss: 0.39; acc:  87.34;   20528 s elapsed
Epoch 15,   451/ 1699; avg loss: 0.41; acc:  85.44;   20672 s elapsed
Epoch 15,   501/ 1699; avg loss: 0.40; acc:  86.69;   20813 s elapsed
Epoch 15,   551/ 1699; avg loss: 0.40; acc:  86.16;   20957 s elapsed
Epoch 15,   601/ 1699; avg loss: 0.40; acc:  86.12;   21097 s elapsed
Epoch 15,   651/ 1699; avg loss: 0.41; acc:  85.59;   21240 s elapsed
Epoch 15,   701/ 1699; avg loss: 0.41; acc:  86.03;   21381 s elapsed
Epoch 15,   751/ 1699; avg loss: 0.42; acc:  85.31;   21524 s elapsed
Epoch 15,   801/ 1699; avg loss: 0.44; acc:  84.56;   21665 s elapsed
Epoch 15,   851/ 1699; avg loss: 0.43; acc:  84.50;   21809 s elapsed
Epoch 15,   901/ 1699; avg loss: 0.48; acc:  83.41;   21958 s elapsed
Epoch 15,   951/ 1699; avg loss: 0.46; acc:  84.06;   22101 s elapsed
Epoch 15,  1001/ 1699; avg loss: 0.45; acc:  84.66;   22245 s elapsed
Epoch 15,  1051/ 1699; avg loss: 0.45; acc:  84.28;   22385 s elapsed
Epoch 15,  1101/ 1699; avg loss: 0.47; acc:  83.56;   22527 s elapsed
Epoch 15,  1151/ 1699; avg loss: 0.45; acc:  84.44;   22668 s elapsed
Epoch 15,  1201/ 1699; avg loss: 0.48; acc:  83.62;   22807 s elapsed
Epoch 15,  1251/ 1699; avg loss: 0.48; acc:  82.94;   22951 s elapsed
Epoch 15,  1301/ 1699; avg loss: 0.47; acc:  83.16;   23098 s elapsed
Epoch 15,  1351/ 1699; avg loss: 0.49; acc:  82.97;   23241 s elapsed
Epoch 15,  1401/ 1699; avg loss: 0.47; acc:  83.56;   23388 s elapsed
Epoch 15,  1451/ 1699; avg loss: 0.49; acc:  82.59;   23530 s elapsed
Epoch 15,  1501/ 1699; avg loss: 0.45; acc:  84.62;   23671 s elapsed
Epoch 15,  1551/ 1699; avg loss: 0.48; acc:  84.00;   23810 s elapsed
Epoch 15,  1601/ 1699; avg loss: 0.49; acc:  82.59;   23953 s elapsed
Epoch 15,  1651/ 1699; avg loss: 0.49; acc:  83.44;   24095 s elapsed
Epoch 15:	 average loss: 0.43	 train accuracy: 85.1489
====================
Evaluating on validation set:
Validation loss: 1.37
Validation accuracy: 65.85
====================

Epoch 16,     1/ 1699; avg loss: 0.31; acc:  92.19;   24243 s elapsed
Epoch 16,    51/ 1699; avg loss: 0.34; acc:  88.72;   24386 s elapsed
Epoch 16,   101/ 1699; avg loss: 0.34; acc:  88.62;   24526 s elapsed
Epoch 16,   151/ 1699; avg loss: 0.32; acc:  89.28;   24671 s elapsed
Epoch 16,   201/ 1699; avg loss: 0.33; acc:  88.75;   24814 s elapsed
Epoch 16,   251/ 1699; avg loss: 0.34; acc:  88.25;   24961 s elapsed
Epoch 16,   301/ 1699; avg loss: 0.37; acc:  87.38;   25103 s elapsed
Epoch 16,   351/ 1699; avg loss: 0.37; acc:  87.34;   25246 s elapsed
Epoch 16,   401/ 1699; avg loss: 0.39; acc:  86.91;   25385 s elapsed
Epoch 16,   451/ 1699; avg loss: 0.38; acc:  87.06;   25528 s elapsed
Epoch 16,   501/ 1699; avg loss: 0.36; acc:  87.78;   25667 s elapsed
Epoch 16,   551/ 1699; avg loss: 0.39; acc:  86.16;   25806 s elapsed
Epoch 16,   601/ 1699; avg loss: 0.41; acc:  86.12;   25952 s elapsed
Epoch 16,   651/ 1699; avg loss: 0.41; acc:  85.69;   26092 s elapsed
Epoch 16,   701/ 1699; avg loss: 0.41; acc:  85.44;   26233 s elapsed
Epoch 16,   751/ 1699; avg loss: 0.41; acc:  85.16;   26372 s elapsed
Epoch 16,   801/ 1699; avg loss: 0.42; acc:  85.19;   26514 s elapsed
Epoch 16,   851/ 1699; avg loss: 0.42; acc:  86.09;   26656 s elapsed
Epoch 16,   901/ 1699; avg loss: 0.43; acc:  84.94;   26799 s elapsed
Epoch 16,   951/ 1699; avg loss: 0.41; acc:  86.28;   26941 s elapsed
Epoch 16,  1001/ 1699; avg loss: 0.45; acc:  84.56;   27082 s elapsed
Epoch 16,  1051/ 1699; avg loss: 0.44; acc:  84.97;   27222 s elapsed
Epoch 16,  1101/ 1699; avg loss: 0.44; acc:  84.88;   27369 s elapsed
Epoch 16,  1151/ 1699; avg loss: 0.43; acc:  84.97;   27513 s elapsed
Epoch 16,  1201/ 1699; avg loss: 0.44; acc:  84.88;   27654 s elapsed
Epoch 16,  1251/ 1699; avg loss: 0.44; acc:  85.06;   27798 s elapsed
Epoch 16,  1301/ 1699; avg loss: 0.45; acc:  84.66;   27938 s elapsed
Epoch 16,  1351/ 1699; avg loss: 0.47; acc:  83.91;   28085 s elapsed
Epoch 16,  1401/ 1699; avg loss: 0.46; acc:  84.62;   28227 s elapsed
Epoch 16,  1451/ 1699; avg loss: 0.46; acc:  83.34;   28372 s elapsed
Epoch 16,  1501/ 1699; avg loss: 0.44; acc:  84.72;   28511 s elapsed
Epoch 16,  1551/ 1699; avg loss: 0.48; acc:  83.97;   28653 s elapsed
Epoch 16,  1601/ 1699; avg loss: 0.45; acc:  83.34;   28796 s elapsed
Epoch 16,  1651/ 1699; avg loss: 0.45; acc:  83.88;   28938 s elapsed
Epoch 16:	 average loss: 0.41	 train accuracy: 85.7835
====================
Evaluating on validation set:
Validation loss: 1.41
Validation accuracy: 65.15
====================

Epoch 17,     1/ 1699; avg loss: 0.27; acc:  85.94;   29086 s elapsed
Epoch 17,    51/ 1699; avg loss: 0.30; acc:  90.12;   29226 s elapsed
Epoch 17,   101/ 1699; avg loss: 0.31; acc:  89.41;   29367 s elapsed
Epoch 17,   151/ 1699; avg loss: 0.31; acc:  89.41;   29509 s elapsed
Epoch 17,   201/ 1699; avg loss: 0.33; acc:  88.69;   29650 s elapsed
Epoch 17,   251/ 1699; avg loss: 0.32; acc:  89.16;   29791 s elapsed
Epoch 17,   301/ 1699; avg loss: 0.33; acc:  88.31;   29931 s elapsed
Epoch 17,   351/ 1699; avg loss: 0.34; acc:  88.62;   30078 s elapsed
Epoch 17,   401/ 1699; avg loss: 0.37; acc:  87.53;   30220 s elapsed
Epoch 17,   451/ 1699; avg loss: 0.38; acc:  87.19;   30363 s elapsed
Epoch 17,   501/ 1699; avg loss: 0.37; acc:  86.66;   30504 s elapsed
Epoch 17,   551/ 1699; avg loss: 0.37; acc:  87.75;   30646 s elapsed
Epoch 17,   601/ 1699; avg loss: 0.38; acc:  86.97;   30789 s elapsed
Epoch 17,   651/ 1699; avg loss: 0.39; acc:  86.78;   30932 s elapsed
Epoch 17,   701/ 1699; avg loss: 0.39; acc:  86.53;   31080 s elapsed
Epoch 17,   751/ 1699; avg loss: 0.41; acc:  85.97;   31222 s elapsed
Epoch 17,   801/ 1699; avg loss: 0.40; acc:  86.91;   31367 s elapsed
Epoch 17,   851/ 1699; avg loss: 0.40; acc:  86.16;   31508 s elapsed
Epoch 17,   901/ 1699; avg loss: 0.41; acc:  85.56;   31649 s elapsed
Epoch 17,   951/ 1699; avg loss: 0.40; acc:  85.78;   31792 s elapsed
Epoch 17,  1001/ 1699; avg loss: 0.40; acc:  87.16;   31936 s elapsed
Epoch 17,  1051/ 1699; avg loss: 0.42; acc:  85.94;   32076 s elapsed
Epoch 17,  1101/ 1699; avg loss: 0.40; acc:  85.97;   32219 s elapsed
Epoch 17,  1151/ 1699; avg loss: 0.43; acc:  85.69;   32359 s elapsed
Epoch 17,  1201/ 1699; avg loss: 0.42; acc:  85.28;   32499 s elapsed
Epoch 17,  1251/ 1699; avg loss: 0.42; acc:  85.56;   32637 s elapsed
Epoch 17,  1301/ 1699; avg loss: 0.44; acc:  84.34;   32780 s elapsed
Epoch 17,  1351/ 1699; avg loss: 0.44; acc:  84.38;   32917 s elapsed
Epoch 17,  1401/ 1699; avg loss: 0.46; acc:  84.62;   33058 s elapsed
Epoch 17,  1451/ 1699; avg loss: 0.43; acc:  85.31;   33197 s elapsed
Epoch 17,  1501/ 1699; avg loss: 0.44; acc:  84.09;   33340 s elapsed
Epoch 17,  1551/ 1699; avg loss: 0.45; acc:  84.59;   33481 s elapsed
Epoch 17,  1601/ 1699; avg loss: 0.45; acc:  84.50;   33625 s elapsed
Epoch 17,  1651/ 1699; avg loss: 0.44; acc:  84.44;   33766 s elapsed
Epoch 17:	 average loss: 0.39	 train accuracy: 86.4679
====================
Evaluating on validation set:
Validation loss: 1.40
Validation accuracy: 66.85
====================

Epoch 18,     1/ 1699; avg loss: 0.15; acc:  96.88;   33924 s elapsed
Epoch 18,    51/ 1699; avg loss: 0.30; acc:  90.38;   34063 s elapsed
Epoch 18,   101/ 1699; avg loss: 0.28; acc:  90.59;   34207 s elapsed
Epoch 18,   151/ 1699; avg loss: 0.29; acc:  90.44;   34346 s elapsed
Epoch 18,   201/ 1699; avg loss: 0.29; acc:  90.41;   34488 s elapsed
Epoch 18,   251/ 1699; avg loss: 0.32; acc:  89.69;   34631 s elapsed
Epoch 18,   301/ 1699; avg loss: 0.32; acc:  88.94;   34778 s elapsed
Epoch 18,   351/ 1699; avg loss: 0.34; acc:  87.75;   34918 s elapsed
Epoch 18,   401/ 1699; avg loss: 0.34; acc:  88.16;   35061 s elapsed
Epoch 18,   451/ 1699; avg loss: 0.36; acc:  88.06;   35202 s elapsed
Epoch 18,   501/ 1699; avg loss: 0.33; acc:  88.56;   35345 s elapsed
Epoch 18,   551/ 1699; avg loss: 0.33; acc:  89.12;   35491 s elapsed
Epoch 18,   601/ 1699; avg loss: 0.37; acc:  87.06;   35631 s elapsed
Epoch 18,   651/ 1699; avg loss: 0.36; acc:  87.75;   35768 s elapsed
Epoch 18,   701/ 1699; avg loss: 0.36; acc:  87.59;   35905 s elapsed
Epoch 18,   751/ 1699; avg loss: 0.37; acc:  86.97;   36049 s elapsed
Epoch 18,   801/ 1699; avg loss: 0.39; acc:  87.12;   36188 s elapsed
Epoch 18,   851/ 1699; avg loss: 0.36; acc:  87.72;   36337 s elapsed
Epoch 18,   901/ 1699; avg loss: 0.38; acc:  87.47;   36475 s elapsed
Epoch 18,   951/ 1699; avg loss: 0.38; acc:  87.41;   36616 s elapsed
Epoch 18,  1001/ 1699; avg loss: 0.38; acc:  87.31;   36760 s elapsed
Epoch 18,  1051/ 1699; avg loss: 0.39; acc:  86.50;   36903 s elapsed
Epoch 18,  1101/ 1699; avg loss: 0.40; acc:  86.62;   37044 s elapsed
Epoch 18,  1151/ 1699; avg loss: 0.43; acc:  85.81;   37186 s elapsed
Epoch 18,  1201/ 1699; avg loss: 0.42; acc:  86.09;   37329 s elapsed
Epoch 18,  1251/ 1699; avg loss: 0.41; acc:  86.41;   37470 s elapsed
Epoch 18,  1301/ 1699; avg loss: 0.41; acc:  86.19;   37614 s elapsed
Epoch 18,  1351/ 1699; avg loss: 0.40; acc:  85.81;   37758 s elapsed
Epoch 18,  1401/ 1699; avg loss: 0.43; acc:  85.25;   37899 s elapsed
Epoch 18,  1451/ 1699; avg loss: 0.43; acc:  84.88;   38044 s elapsed
Epoch 18,  1501/ 1699; avg loss: 0.46; acc:  85.47;   38187 s elapsed
Epoch 18,  1551/ 1699; avg loss: 0.40; acc:  85.75;   38328 s elapsed
Epoch 18,  1601/ 1699; avg loss: 0.44; acc:  84.41;   38471 s elapsed
Epoch 18,  1651/ 1699; avg loss: 0.47; acc:  83.78;   38615 s elapsed
Epoch 18:	 average loss: 0.38	 train accuracy: 87.2341
====================
Evaluating on validation set:
Validation loss: 1.42
Validation accuracy: 65.85
====================

Epoch 19,     1/ 1699; avg loss: 0.33; acc:  89.06;   38764 s elapsed
Epoch 19,    51/ 1699; avg loss: 0.28; acc:  91.41;   38906 s elapsed
Epoch 19,   101/ 1699; avg loss: 0.27; acc:  90.91;   39044 s elapsed
Epoch 19,   151/ 1699; avg loss: 0.28; acc:  90.34;   39190 s elapsed
Epoch 19,   201/ 1699; avg loss: 0.30; acc:  90.19;   39334 s elapsed
Epoch 19,   251/ 1699; avg loss: 0.29; acc:  90.44;   39475 s elapsed
Epoch 19,   301/ 1699; avg loss: 0.30; acc:  90.25;   39618 s elapsed
Epoch 19,   351/ 1699; avg loss: 0.29; acc:  89.50;   39759 s elapsed
Epoch 19,   401/ 1699; avg loss: 0.32; acc:  89.19;   39901 s elapsed
Epoch 19,   451/ 1699; avg loss: 0.32; acc:  89.75;   40045 s elapsed
Epoch 19,   501/ 1699; avg loss: 0.33; acc:  88.53;   40186 s elapsed
Epoch 19,   551/ 1699; avg loss: 0.35; acc:  88.16;   40325 s elapsed
Epoch 19,   601/ 1699; avg loss: 0.35; acc:  87.91;   40468 s elapsed
Epoch 19,   651/ 1699; avg loss: 0.35; acc:  88.28;   40609 s elapsed
Epoch 19,   701/ 1699; avg loss: 0.36; acc:  87.44;   40753 s elapsed
Epoch 19,   751/ 1699; avg loss: 0.34; acc:  88.31;   40893 s elapsed
Epoch 19,   801/ 1699; avg loss: 0.36; acc:  87.62;   41035 s elapsed
Epoch 19,   851/ 1699; avg loss: 0.39; acc:  86.84;   41175 s elapsed
Epoch 19,   901/ 1699; avg loss: 0.37; acc:  86.16;   41315 s elapsed
Epoch 19,   951/ 1699; avg loss: 0.37; acc:  87.56;   41456 s elapsed
Epoch 19,  1001/ 1699; avg loss: 0.39; acc:  86.94;   41596 s elapsed
Epoch 19,  1051/ 1699; avg loss: 0.41; acc:  86.75;   41737 s elapsed
Epoch 19,  1101/ 1699; avg loss: 0.37; acc:  87.41;   41883 s elapsed
Epoch 19,  1151/ 1699; avg loss: 0.41; acc:  85.28;   42027 s elapsed
Epoch 19,  1201/ 1699; avg loss: 0.39; acc:  87.28;   42168 s elapsed
Epoch 19,  1251/ 1699; avg loss: 0.40; acc:  85.38;   42310 s elapsed
Epoch 19,  1301/ 1699; avg loss: 0.40; acc:  86.38;   42452 s elapsed
Epoch 19,  1351/ 1699; avg loss: 0.43; acc:  85.16;   42590 s elapsed
Epoch 19,  1401/ 1699; avg loss: 0.40; acc:  86.62;   42734 s elapsed
Epoch 19,  1451/ 1699; avg loss: 0.40; acc:  86.12;   42879 s elapsed
Epoch 19,  1501/ 1699; avg loss: 0.41; acc:  86.41;   43025 s elapsed
Epoch 19,  1551/ 1699; avg loss: 0.41; acc:  85.69;   43166 s elapsed
Epoch 19,  1601/ 1699; avg loss: 0.41; acc:  86.38;   43306 s elapsed
Epoch 19,  1651/ 1699; avg loss: 0.41; acc:  86.00;   43451 s elapsed
Epoch 19:	 average loss: 0.36	 train accuracy: 87.693
====================
Evaluating on validation set:
Validation loss: 1.44
Validation accuracy: 66.1
====================

Epoch 20,     1/ 1699; avg loss: 0.17; acc:  95.31;   43606 s elapsed
Epoch 20,    51/ 1699; avg loss: 0.27; acc:  91.28;   43749 s elapsed
Epoch 20,   101/ 1699; avg loss: 0.26; acc:  91.56;   43891 s elapsed
Epoch 20,   151/ 1699; avg loss: 0.26; acc:  91.28;   44031 s elapsed
Epoch 20,   201/ 1699; avg loss: 0.27; acc:  90.91;   44175 s elapsed
Epoch 20,   251/ 1699; avg loss: 0.27; acc:  91.03;   44320 s elapsed
Epoch 20,   301/ 1699; avg loss: 0.27; acc:  90.72;   44461 s elapsed
Epoch 20,   351/ 1699; avg loss: 0.29; acc:  90.06;   44600 s elapsed
Epoch 20,   401/ 1699; avg loss: 0.28; acc:  90.94;   44736 s elapsed
Epoch 20,   451/ 1699; avg loss: 0.30; acc:  89.59;   44877 s elapsed
Epoch 20,   501/ 1699; avg loss: 0.32; acc:  89.06;   45016 s elapsed
Epoch 20,   551/ 1699; avg loss: 0.33; acc:  88.31;   45158 s elapsed
Epoch 20,   601/ 1699; avg loss: 0.34; acc:  88.22;   45300 s elapsed
Epoch 20,   651/ 1699; avg loss: 0.35; acc:  88.44;   45441 s elapsed
Epoch 20,   701/ 1699; avg loss: 0.34; acc:  88.47;   45584 s elapsed
Epoch 20,   751/ 1699; avg loss: 0.31; acc:  89.12;   45729 s elapsed
Epoch 20,   801/ 1699; avg loss: 0.35; acc:  88.06;   45871 s elapsed
Epoch 20,   851/ 1699; avg loss: 0.35; acc:  88.19;   46016 s elapsed
Epoch 20,   901/ 1699; avg loss: 0.34; acc:  88.41;   46162 s elapsed
Epoch 20,   951/ 1699; avg loss: 0.35; acc:  88.56;   46301 s elapsed
Epoch 20,  1001/ 1699; avg loss: 0.40; acc:  86.81;   46447 s elapsed
Epoch 20,  1051/ 1699; avg loss: 0.36; acc:  87.62;   46586 s elapsed
Epoch 20,  1101/ 1699; avg loss: 0.37; acc:  87.47;   46726 s elapsed
Epoch 20,  1151/ 1699; avg loss: 0.37; acc:  87.47;   46868 s elapsed
Epoch 20,  1201/ 1699; avg loss: 0.38; acc:  86.41;   47009 s elapsed
Epoch 20,  1251/ 1699; avg loss: 0.38; acc:  87.16;   47157 s elapsed
Epoch 20,  1301/ 1699; avg loss: 0.37; acc:  87.34;   47296 s elapsed
Epoch 20,  1351/ 1699; avg loss: 0.40; acc:  86.94;   47441 s elapsed
Epoch 20,  1401/ 1699; avg loss: 0.38; acc:  87.22;   47585 s elapsed
Epoch 20,  1451/ 1699; avg loss: 0.37; acc:  87.66;   47723 s elapsed
Epoch 20,  1501/ 1699; avg loss: 0.41; acc:  86.69;   47870 s elapsed
Epoch 20,  1551/ 1699; avg loss: 0.42; acc:  85.78;   48011 s elapsed
Epoch 20,  1601/ 1699; avg loss: 0.39; acc:  86.03;   48153 s elapsed
Epoch 20,  1651/ 1699; avg loss: 0.40; acc:  86.00;   48296 s elapsed
Epoch 20:	 average loss: 0.34	 train accuracy: 88.3829
====================
Evaluating on validation set:
Validation loss: 1.49
Validation accuracy: 66.65
====================

Epoch 21,     1/ 1699; avg loss: 0.23; acc:  93.75;   48447 s elapsed
Epoch 21,    51/ 1699; avg loss: 0.24; acc:  92.44;   48589 s elapsed
Epoch 21,   101/ 1699; avg loss: 0.25; acc:  92.06;   48730 s elapsed
Epoch 21,   151/ 1699; avg loss: 0.26; acc:  91.12;   48877 s elapsed
Epoch 21,   201/ 1699; avg loss: 0.26; acc:  91.84;   49019 s elapsed
Epoch 21,   251/ 1699; avg loss: 0.26; acc:  91.59;   49165 s elapsed
Epoch 21,   301/ 1699; avg loss: 0.26; acc:  91.09;   49304 s elapsed
Epoch 21,   351/ 1699; avg loss: 0.28; acc:  90.53;   49450 s elapsed
Epoch 21,   401/ 1699; avg loss: 0.28; acc:  90.38;   49586 s elapsed
Epoch 21,   451/ 1699; avg loss: 0.28; acc:  90.75;   49731 s elapsed
Epoch 21,   501/ 1699; avg loss: 0.26; acc:  91.41;   49874 s elapsed
Epoch 21,   551/ 1699; avg loss: 0.28; acc:  90.22;   50017 s elapsed
Epoch 21,   601/ 1699; avg loss: 0.30; acc:  89.41;   50163 s elapsed
Epoch 21,   651/ 1699; avg loss: 0.30; acc:  90.84;   50306 s elapsed
Epoch 21,   701/ 1699; avg loss: 0.32; acc:  89.38;   50447 s elapsed
Epoch 21,   751/ 1699; avg loss: 0.31; acc:  89.47;   50589 s elapsed
Epoch 21,   801/ 1699; avg loss: 0.32; acc:  88.81;   50731 s elapsed
Epoch 21,   851/ 1699; avg loss: 0.33; acc:  88.66;   50874 s elapsed
Epoch 21,   901/ 1699; avg loss: 0.34; acc:  88.28;   51015 s elapsed
Epoch 21,   951/ 1699; avg loss: 0.35; acc:  87.88;   51157 s elapsed
Epoch 21,  1001/ 1699; avg loss: 0.34; acc:  89.31;   51298 s elapsed
Epoch 21,  1051/ 1699; avg loss: 0.34; acc:  88.84;   51443 s elapsed
Epoch 21,  1101/ 1699; avg loss: 0.35; acc:  88.25;   51588 s elapsed
Epoch 21,  1151/ 1699; avg loss: 0.36; acc:  87.91;   51730 s elapsed
Epoch 21,  1201/ 1699; avg loss: 0.37; acc:  87.25;   51870 s elapsed
Epoch 21,  1251/ 1699; avg loss: 0.36; acc:  87.53;   52013 s elapsed
Epoch 21,  1301/ 1699; avg loss: 0.35; acc:  87.94;   52150 s elapsed
Epoch 21,  1351/ 1699; avg loss: 0.35; acc:  88.75;   52289 s elapsed
Epoch 21,  1401/ 1699; avg loss: 0.36; acc:  88.34;   52433 s elapsed
Epoch 21,  1451/ 1699; avg loss: 0.40; acc:  85.91;   52573 s elapsed
Epoch 21,  1501/ 1699; avg loss: 0.37; acc:  87.97;   52714 s elapsed
Epoch 21,  1551/ 1699; avg loss: 0.41; acc:  85.47;   52858 s elapsed
Epoch 21,  1601/ 1699; avg loss: 0.42; acc:  85.50;   53001 s elapsed
Epoch 21,  1651/ 1699; avg loss: 0.42; acc:  86.25;   53145 s elapsed
Epoch 21:	 average loss: 0.33	 train accuracy: 89.07
====================
Evaluating on validation set:
Validation loss: 1.65
Validation accuracy: 64.8
====================

Epoch 22,     1/ 1699; avg loss: 0.21; acc:  93.75;   53298 s elapsed
Epoch 22,    51/ 1699; avg loss: 0.24; acc:  92.62;   53437 s elapsed
Epoch 22,   101/ 1699; avg loss: 0.22; acc:  93.31;   53580 s elapsed
Epoch 22,   151/ 1699; avg loss: 0.24; acc:  92.00;   53724 s elapsed
Epoch 22,   201/ 1699; avg loss: 0.22; acc:  93.06;   53864 s elapsed
Epoch 22,   251/ 1699; avg loss: 0.25; acc:  91.47;   54004 s elapsed
Epoch 22,   301/ 1699; avg loss: 0.24; acc:  92.59;   54144 s elapsed
Epoch 22,   351/ 1699; avg loss: 0.26; acc:  91.78;   54288 s elapsed
Epoch 22,   401/ 1699; avg loss: 0.26; acc:  91.34;   54432 s elapsed
Epoch 22,   451/ 1699; avg loss: 0.27; acc:  90.88;   54573 s elapsed
Epoch 22,   501/ 1699; avg loss: 0.29; acc:  90.38;   54715 s elapsed
Epoch 22,   551/ 1699; avg loss: 0.31; acc:  89.56;   54859 s elapsed
Epoch 22,   601/ 1699; avg loss: 0.30; acc:  89.91;   55000 s elapsed
Epoch 22,   651/ 1699; avg loss: 0.30; acc:  89.75;   55139 s elapsed
Epoch 22,   701/ 1699; avg loss: 0.32; acc:  88.59;   55280 s elapsed
Epoch 22,   751/ 1699; avg loss: 0.29; acc:  90.31;   55423 s elapsed
Epoch 22,   801/ 1699; avg loss: 0.30; acc:  89.44;   55564 s elapsed
Epoch 22,   851/ 1699; avg loss: 0.33; acc:  89.16;   55705 s elapsed
Epoch 22,   901/ 1699; avg loss: 0.33; acc:  89.16;   55845 s elapsed
Epoch 22,   951/ 1699; avg loss: 0.32; acc:  89.69;   55985 s elapsed
Epoch 22,  1001/ 1699; avg loss: 0.32; acc:  88.53;   56124 s elapsed
Epoch 22,  1051/ 1699; avg loss: 0.33; acc:  88.62;   56272 s elapsed
Epoch 22,  1101/ 1699; avg loss: 0.34; acc:  88.28;   56412 s elapsed
Epoch 22,  1151/ 1699; avg loss: 0.37; acc:  88.31;   56559 s elapsed
Epoch 22,  1201/ 1699; avg loss: 0.34; acc:  87.75;   56704 s elapsed
Epoch 22,  1251/ 1699; avg loss: 0.33; acc:  88.78;   56851 s elapsed
Epoch 22,  1301/ 1699; avg loss: 0.35; acc:  88.22;   56993 s elapsed
Epoch 22,  1351/ 1699; avg loss: 0.36; acc:  88.09;   57137 s elapsed
Epoch 22,  1401/ 1699; avg loss: 0.36; acc:  88.22;   57278 s elapsed
Epoch 22,  1451/ 1699; avg loss: 0.36; acc:  87.34;   57418 s elapsed
Epoch 22,  1501/ 1699; avg loss: 0.38; acc:  87.03;   57564 s elapsed
Epoch 22,  1551/ 1699; avg loss: 0.37; acc:  87.03;   57706 s elapsed
Epoch 22,  1601/ 1699; avg loss: 0.34; acc:  88.50;   57847 s elapsed
Epoch 22,  1651/ 1699; avg loss: 0.37; acc:  88.00;   57991 s elapsed
Epoch 22:	 average loss: 0.31	 train accuracy: 89.5593
====================
Evaluating on validation set:
Validation loss: 1.60
Validation accuracy: 66.5
====================

Epoch 23,     1/ 1699; avg loss: 0.22; acc:  93.75;   58140 s elapsed
Epoch 23,    51/ 1699; avg loss: 0.22; acc:  92.97;   58281 s elapsed
Epoch 23,   101/ 1699; avg loss: 0.21; acc:  93.56;   58419 s elapsed
Epoch 23,   151/ 1699; avg loss: 0.21; acc:  93.78;   58560 s elapsed
Epoch 23,   201/ 1699; avg loss: 0.20; acc:  93.31;   58705 s elapsed
Epoch 23,   251/ 1699; avg loss: 0.25; acc:  91.56;   58845 s elapsed
Epoch 23,   301/ 1699; avg loss: 0.23; acc:  92.78;   58986 s elapsed
Epoch 23,   351/ 1699; avg loss: 0.25; acc:  92.28;   59132 s elapsed
Epoch 23,   401/ 1699; avg loss: 0.24; acc:  92.28;   59272 s elapsed
Epoch 23,   451/ 1699; avg loss: 0.26; acc:  91.25;   59413 s elapsed
Epoch 23,   501/ 1699; avg loss: 0.26; acc:  91.12;   59556 s elapsed
Epoch 23,   551/ 1699; avg loss: 0.26; acc:  91.56;   59698 s elapsed
Epoch 23,   601/ 1699; avg loss: 0.26; acc:  91.00;   59839 s elapsed
Epoch 23,   651/ 1699; avg loss: 0.28; acc:  90.69;   59983 s elapsed
Epoch 23,   701/ 1699; avg loss: 0.29; acc:  90.03;   60123 s elapsed
Epoch 23,   751/ 1699; avg loss: 0.28; acc:  90.38;   60266 s elapsed
Epoch 23,   801/ 1699; avg loss: 0.31; acc:  89.88;   60413 s elapsed
Epoch 23,   851/ 1699; avg loss: 0.32; acc:  88.62;   60554 s elapsed
Epoch 23,   901/ 1699; avg loss: 0.30; acc:  89.84;   60697 s elapsed
Epoch 23,   951/ 1699; avg loss: 0.33; acc:  88.53;   60838 s elapsed
Epoch 23,  1001/ 1699; avg loss: 0.34; acc:  88.22;   60982 s elapsed
Epoch 23,  1051/ 1699; avg loss: 0.33; acc:  89.06;   61123 s elapsed
Epoch 23,  1101/ 1699; avg loss: 0.33; acc:  89.53;   61268 s elapsed
Epoch 23,  1151/ 1699; avg loss: 0.34; acc:  88.94;   61407 s elapsed
Epoch 23,  1201/ 1699; avg loss: 0.35; acc:  89.00;   61546 s elapsed
Epoch 23,  1251/ 1699; avg loss: 0.32; acc:  89.50;   61689 s elapsed
Epoch 23,  1301/ 1699; avg loss: 0.34; acc:  89.44;   61830 s elapsed
Epoch 23,  1351/ 1699; avg loss: 0.34; acc:  89.25;   61974 s elapsed
Epoch 23,  1401/ 1699; avg loss: 0.36; acc:  88.09;   62113 s elapsed
Epoch 23,  1451/ 1699; avg loss: 0.33; acc:  88.44;   62260 s elapsed
Epoch 23,  1501/ 1699; avg loss: 0.34; acc:  88.25;   62405 s elapsed
Epoch 23,  1551/ 1699; avg loss: 0.36; acc:  87.72;   62546 s elapsed
Epoch 23,  1601/ 1699; avg loss: 0.35; acc:  88.56;   62689 s elapsed
Epoch 23,  1651/ 1699; avg loss: 0.36; acc:  87.88;   62832 s elapsed
Epoch 23:	 average loss: 0.30	 train accuracy: 90.1406
====================
Evaluating on validation set:
Validation loss: 1.67
Validation accuracy: 66.3
====================

Epoch 24,     1/ 1699; avg loss: 0.20; acc:  92.19;   62977 s elapsed
Epoch 24,    51/ 1699; avg loss: 0.22; acc:  93.16;   63122 s elapsed
Epoch 24,   101/ 1699; avg loss: 0.19; acc:  93.91;   63262 s elapsed
Epoch 24,   151/ 1699; avg loss: 0.21; acc:  92.62;   63405 s elapsed
Epoch 24,   201/ 1699; avg loss: 0.21; acc:  93.19;   63547 s elapsed
Epoch 24,   251/ 1699; avg loss: 0.22; acc:  93.06;   63689 s elapsed
Epoch 24,   301/ 1699; avg loss: 0.24; acc:  92.22;   63828 s elapsed
Epoch 24,   351/ 1699; avg loss: 0.23; acc:  92.09;   63966 s elapsed
Epoch 24,   401/ 1699; avg loss: 0.25; acc:  91.56;   64108 s elapsed
Epoch 24,   451/ 1699; avg loss: 0.25; acc:  92.12;   64248 s elapsed
Epoch 24,   501/ 1699; avg loss: 0.25; acc:  92.28;   64392 s elapsed
Epoch 24,   551/ 1699; avg loss: 0.25; acc:  92.41;   64537 s elapsed
Epoch 24,   601/ 1699; avg loss: 0.24; acc:  92.03;   64680 s elapsed
Epoch 24,   651/ 1699; avg loss: 0.28; acc:  90.00;   64823 s elapsed
Epoch 24,   701/ 1699; avg loss: 0.26; acc:  91.84;   64968 s elapsed
Epoch 24,   751/ 1699; avg loss: 0.28; acc:  90.59;   65112 s elapsed
Epoch 24,   801/ 1699; avg loss: 0.28; acc:  90.53;   65252 s elapsed
Epoch 24,   851/ 1699; avg loss: 0.30; acc:  89.72;   65394 s elapsed
Epoch 24,   901/ 1699; avg loss: 0.30; acc:  90.44;   65536 s elapsed
Epoch 24,   951/ 1699; avg loss: 0.28; acc:  90.69;   65680 s elapsed
Epoch 24,  1001/ 1699; avg loss: 0.30; acc:  89.81;   65824 s elapsed
Epoch 24,  1051/ 1699; avg loss: 0.31; acc:  90.00;   65964 s elapsed
Epoch 24,  1101/ 1699; avg loss: 0.32; acc:  89.25;   66105 s elapsed
Epoch 24,  1151/ 1699; avg loss: 0.30; acc:  89.78;   66248 s elapsed
Epoch 24,  1201/ 1699; avg loss: 0.33; acc:  88.47;   66388 s elapsed
Epoch 24,  1251/ 1699; avg loss: 0.30; acc:  89.34;   66532 s elapsed
Epoch 24,  1301/ 1699; avg loss: 0.35; acc:  88.53;   66679 s elapsed
Epoch 24,  1351/ 1699; avg loss: 0.31; acc:  90.06;   66819 s elapsed
Epoch 24,  1401/ 1699; avg loss: 0.32; acc:  89.25;   66959 s elapsed
Epoch 24,  1451/ 1699; avg loss: 0.31; acc:  89.66;   67102 s elapsed
Epoch 24,  1501/ 1699; avg loss: 0.33; acc:  88.62;   67245 s elapsed
Epoch 24,  1551/ 1699; avg loss: 0.34; acc:  88.19;   67386 s elapsed
Epoch 24,  1601/ 1699; avg loss: 0.34; acc:  88.59;   67527 s elapsed
Epoch 24,  1651/ 1699; avg loss: 0.33; acc:  88.41;   67666 s elapsed
Epoch 24:	 average loss: 0.28	 train accuracy: 90.6162
====================
Evaluating on validation set:
Validation loss: 1.71
Validation accuracy: 65.7
====================

Epoch 25,     1/ 1699; avg loss: 0.17; acc:  93.75;   67819 s elapsed
Epoch 25,    51/ 1699; avg loss: 0.20; acc:  93.72;   67960 s elapsed
Epoch 25,   101/ 1699; avg loss: 0.20; acc:  93.41;   68103 s elapsed
Epoch 25,   151/ 1699; avg loss: 0.20; acc:  93.69;   68246 s elapsed
Epoch 25,   201/ 1699; avg loss: 0.20; acc:  93.50;   68386 s elapsed
Epoch 25,   251/ 1699; avg loss: 0.19; acc:  93.94;   68527 s elapsed
Epoch 25,   301/ 1699; avg loss: 0.20; acc:  93.44;   68671 s elapsed
Epoch 25,   351/ 1699; avg loss: 0.22; acc:  93.12;   68815 s elapsed
Epoch 25,   401/ 1699; avg loss: 0.23; acc:  92.41;   68957 s elapsed
Epoch 25,   451/ 1699; avg loss: 0.25; acc:  91.59;   69099 s elapsed
Epoch 25,   501/ 1699; avg loss: 0.22; acc:  92.88;   69241 s elapsed
Epoch 25,   551/ 1699; avg loss: 0.25; acc:  91.47;   69389 s elapsed
Epoch 25,   601/ 1699; avg loss: 0.24; acc:  92.28;   69534 s elapsed
Epoch 25,   651/ 1699; avg loss: 0.26; acc:  92.03;   69674 s elapsed
Epoch 25,   701/ 1699; avg loss: 0.27; acc:  91.34;   69820 s elapsed
Epoch 25,   751/ 1699; avg loss: 0.23; acc:  92.22;   69958 s elapsed
Epoch 25,   801/ 1699; avg loss: 0.27; acc:  91.28;   70098 s elapsed
Epoch 25,   851/ 1699; avg loss: 0.29; acc:  90.78;   70239 s elapsed
Epoch 25,   901/ 1699; avg loss: 0.29; acc:  90.81;   70379 s elapsed
Epoch 25,   951/ 1699; avg loss: 0.29; acc:  90.00;   70519 s elapsed
Epoch 25,  1001/ 1699; avg loss: 0.30; acc:  89.84;   70660 s elapsed
Epoch 25,  1051/ 1699; avg loss: 0.28; acc:  91.09;   70803 s elapsed
Epoch 25,  1101/ 1699; avg loss: 0.29; acc:  90.56;   70944 s elapsed
Epoch 25,  1151/ 1699; avg loss: 0.29; acc:  90.75;   71086 s elapsed
Epoch 25,  1201/ 1699; avg loss: 0.33; acc:  88.56;   71228 s elapsed
Epoch 25,  1251/ 1699; avg loss: 0.31; acc:  89.31;   71372 s elapsed
Epoch 25,  1301/ 1699; avg loss: 0.34; acc:  88.72;   71515 s elapsed
Epoch 25,  1351/ 1699; avg loss: 0.34; acc:  88.81;   71658 s elapsed
Epoch 25,  1401/ 1699; avg loss: 0.32; acc:  89.69;   71800 s elapsed
Epoch 25,  1451/ 1699; avg loss: 0.32; acc:  88.97;   71942 s elapsed
Epoch 25,  1501/ 1699; avg loss: 0.33; acc:  89.25;   72082 s elapsed
Epoch 25,  1551/ 1699; avg loss: 0.32; acc:  88.97;   72223 s elapsed
Epoch 25,  1601/ 1699; avg loss: 0.31; acc:  89.16;   72369 s elapsed
run.sh: line 14: 30864 Terminated              python train.py -train_from models/$mf -traindata $d/cbtest_NE_train.txt.pt -validdata $d/cbtest_NE_valid_2000ex.txt.pt -dict $d/cbtest_NE_train.txtdict.pt -save_model $m -gru_size 384 -embed_size 384 -batch_size 64 -dropout 0.1 -epochs $epoch -learning_rate $lr -gpu 0 -log_interval 50
